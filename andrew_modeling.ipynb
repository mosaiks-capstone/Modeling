{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe56655",
   "metadata": {},
   "source": [
    "# Modeling Agricultural Variables\n",
    "## Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b4f19f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import multiprocessing as mp\n",
    "\n",
    "import geopandas as gpd\n",
    "import pyarrow\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, r2_score, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.linalg import LinAlgWarning\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.utils import check_random_state, resample\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f0591f-583f-4945-b1d2-0323ae715531",
   "metadata": {},
   "source": [
    "## Read in Data\n",
    "\n",
    "We first read in the aggregated features and ground-truth data joined in  feature_preprocessing.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f593b6f-5740-41de-b785-3a4555428899",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>sea_unq</th>\n",
       "      <th>index_left</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>0_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>0_4</th>\n",
       "      <th>0_5</th>\n",
       "      <th>...</th>\n",
       "      <th>prop_mix</th>\n",
       "      <th>log_maize</th>\n",
       "      <th>log_sweetpotatoes</th>\n",
       "      <th>log_groundnuts</th>\n",
       "      <th>log_soybeans</th>\n",
       "      <th>loss_ind</th>\n",
       "      <th>drought_loss_ind</th>\n",
       "      <th>flood_loss_ind</th>\n",
       "      <th>animal_loss_ind</th>\n",
       "      <th>pest_loss_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>46302.000000</td>\n",
       "      <td>27.807993</td>\n",
       "      <td>-13.659357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.058626</td>\n",
       "      <td>5.269229</td>\n",
       "      <td>7.640386</td>\n",
       "      <td>6.977090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>7</td>\n",
       "      <td>51611.666667</td>\n",
       "      <td>28.634660</td>\n",
       "      <td>-13.772690</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181102</td>\n",
       "      <td>3.387211</td>\n",
       "      <td>0.689155</td>\n",
       "      <td>7.707512</td>\n",
       "      <td>7.113191</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>9</td>\n",
       "      <td>44806.714286</td>\n",
       "      <td>27.406446</td>\n",
       "      <td>-12.905428</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069018</td>\n",
       "      <td>2.703935</td>\n",
       "      <td>8.486127</td>\n",
       "      <td>-1.408767</td>\n",
       "      <td>7.141370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>10</td>\n",
       "      <td>44644.411765</td>\n",
       "      <td>27.381719</td>\n",
       "      <td>-12.962298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.714757</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>3.354421</td>\n",
       "      <td>6.929734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>12</td>\n",
       "      <td>47769.000000</td>\n",
       "      <td>28.014660</td>\n",
       "      <td>-12.889357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.786884</td>\n",
       "      <td>8.509161</td>\n",
       "      <td>2.852125</td>\n",
       "      <td>0.798508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>347</td>\n",
       "      <td>22038.000000</td>\n",
       "      <td>25.204660</td>\n",
       "      <td>-14.879357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.952872</td>\n",
       "      <td>8.294050</td>\n",
       "      <td>8.079163</td>\n",
       "      <td>7.021973</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>348</td>\n",
       "      <td>19562.000000</td>\n",
       "      <td>24.774660</td>\n",
       "      <td>-14.799357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.642350</td>\n",
       "      <td>8.070906</td>\n",
       "      <td>8.429997</td>\n",
       "      <td>8.006368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>355</td>\n",
       "      <td>15659.538462</td>\n",
       "      <td>24.260045</td>\n",
       "      <td>-14.563972</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.508878</td>\n",
       "      <td>7.665441</td>\n",
       "      <td>8.211719</td>\n",
       "      <td>5.238174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>356</td>\n",
       "      <td>19411.000000</td>\n",
       "      <td>24.752993</td>\n",
       "      <td>-14.764357</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.608263</td>\n",
       "      <td>9.042113</td>\n",
       "      <td>8.224773</td>\n",
       "      <td>8.028346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>388</td>\n",
       "      <td>21710.181818</td>\n",
       "      <td>25.116478</td>\n",
       "      <td>-14.652084</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.939201</td>\n",
       "      <td>9.367183</td>\n",
       "      <td>8.098897</td>\n",
       "      <td>7.336848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539 rows Ã— 12044 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  sea_unq    index_left        lon        lat       0_1       0_2  \\\n",
       "0    2016.0        1  46302.000000  27.807993 -13.659357  0.000000  0.000000   \n",
       "1    2016.0        7  51611.666667  28.634660 -13.772690  0.001141  0.000329   \n",
       "2    2016.0        9  44806.714286  27.406446 -12.905428  0.000006  0.000006   \n",
       "3    2016.0       10  44644.411765  27.381719 -12.962298  0.000000  0.000000   \n",
       "4    2016.0       12  47769.000000  28.014660 -12.889357  0.000000  0.000000   \n",
       "..      ...      ...           ...        ...        ...       ...       ...   \n",
       "534  2021.0      347  22038.000000  25.204660 -14.879357  0.000000  0.000000   \n",
       "535  2021.0      348  19562.000000  24.774660 -14.799357  0.000000  0.000000   \n",
       "536  2021.0      355  15659.538462  24.260045 -14.563972  0.000038  0.000038   \n",
       "537  2021.0      356  19411.000000  24.752993 -14.764357  0.000158  0.000158   \n",
       "538  2021.0      388  21710.181818  25.116478 -14.652084  0.000076  0.000076   \n",
       "\n",
       "          0_3       0_4       0_5  ...  prop_mix  log_maize  \\\n",
       "0    0.000000  0.000000  0.000000  ...  0.000000   4.058626   \n",
       "1    0.000329  0.000329  0.000000  ...  0.181102   3.387211   \n",
       "2    0.000006  0.000006  0.000004  ...  0.069018   2.703935   \n",
       "3    0.000000  0.000000  0.000000  ...  0.000000   3.714757   \n",
       "4    0.000000  0.000000  0.000000  ...  0.000000   2.786884   \n",
       "..        ...       ...       ...  ...       ...        ...   \n",
       "534  0.000000  0.000000  0.000000  ...  0.000000   7.952872   \n",
       "535  0.000018  0.000039  0.000071  ...  0.000000   7.642350   \n",
       "536  0.001014  0.000033  0.000028  ...  0.000000   7.508878   \n",
       "537  0.000246  0.000040  0.000038  ...  0.000000   7.608263   \n",
       "538  0.000106  0.000075  0.000046  ...  0.000000   7.939201   \n",
       "\n",
       "     log_sweetpotatoes  log_groundnuts  log_soybeans  loss_ind  \\\n",
       "0             5.269229        7.640386      6.977090       0.0   \n",
       "1             0.689155        7.707512      7.113191       1.0   \n",
       "2             8.486127       -1.408767      7.141370       1.0   \n",
       "3             2.525729        3.354421      6.929734       1.0   \n",
       "4             8.509161        2.852125      0.798508       1.0   \n",
       "..                 ...             ...           ...       ...   \n",
       "534           8.294050        8.079163      7.021973       1.0   \n",
       "535           8.070906        8.429997      8.006368       1.0   \n",
       "536           7.665441        8.211719      5.238174       1.0   \n",
       "537           9.042113        8.224773      8.028346       1.0   \n",
       "538           9.367183        8.098897      7.336848       0.0   \n",
       "\n",
       "     drought_loss_ind  flood_loss_ind  animal_loss_ind  pest_loss_ind  \n",
       "0                 0.0             0.0              0.0            0.0  \n",
       "1                 1.0             0.0              0.0            0.0  \n",
       "2                 0.0             0.0              0.0            0.0  \n",
       "3                 0.0             0.0              0.0            0.0  \n",
       "4                 0.0             0.0              0.0            0.0  \n",
       "..                ...             ...              ...            ...  \n",
       "534               1.0             0.0              0.0            0.0  \n",
       "535               1.0             0.0              0.0            0.0  \n",
       "536               0.0             0.0              0.0            0.0  \n",
       "537               0.0             0.0              0.0            0.0  \n",
       "538               0.0             0.0              0.0            0.0  \n",
       "\n",
       "[539 rows x 12044 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_features = pd.read_csv(\"/capstone/mosaiks/repos/modeling/data/model_directory/SEA_averaged_features_simple_impute_modeltrain.csv\")\n",
    "grouped_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a6fa15-f87e-4244-83a8-af8dd2a409dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /Users/andrewbartnik/.conda/envs/mosaiks/share/proj failed\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAGdCAYAAAAR0wqoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABqoUlEQVR4nO3dd3xT9foH8M9J0qRNR7r3pIu2rLL3FHABehXFASpuxXm9Kvc60HsRve7tT0URvSoORBFBEdm7QOkCuvdeSdrsnPP7o1IpTdukTXIynvfr1dfLJCfnPB7aPPmu58twHMeBEEIIIS5HwHcAhBBCCLENSvKEEEKIi6IkTwghhLgoSvKEEEKIi6IkTwghhLgoSvKEEEKIi6IkTwghhLgoSvKEEEKIixLxHcBQsSyL2tpa+Pr6gmEYvsMhhBBCrIbjOCiVSkRGRkIgsLxd7vRJvra2FjExMXyHQQghhNhMVVUVoqOjLX6f0yd5X19fAF03wM/Pj+doCCGEEOtRKBSIiYnpznWWcvokf76L3s/Pj5I8IYQQlzTY4WiaeEcIIYS4KEryhBBCiIuiJE8IIYS4KEryhBBCiIuiJE8IIYS4KEryhBBCiIuiJE8IIYS4KEryhBBCiIuiJE8IIYS4KEryhBBCiIuiJE8IIYS4KEryhBBCiIuiJE8IIYS4KEryhBCXpTOwfIdACK8oyRNCXJZYRB9xxL3RXwAhxOWpdQaUN3fyHQYhdifiOwBCCLEVjuOw+1wjXtx+FkKBAD+tmgYPIbVtiPugJE8IcUln6hR48vscnK6WI8xPgh/uowRP3A/9xhNCXNLB4macrpYjPcIPm++bhkh/L75DIsTuqCVPCHFJ4+IC8NI1I7FodCSk4p4fdUaWg1DA8BQZIfZDSZ4Q4pIyYwOQGRtg8jVK8MRdUHc9IYQQ4qIoyRNCCCEuipI8IYQQ4qIoyRNCCCEuipI8IYQQ4qIoyRNCCCEuipbQEUJcnkZvRG51O05UtiM+SIpLR0TwHRIhdkFJnhDiFgK8JbhnViLfYRBiV9RdTwhxeZ4eQiSF+vAdBiF2R0meEEIIcVGU5AkhLo3jOHRoDXyHQQgvKMkTQlwawzDwkdD0I+KeKMkTQlzWvsImcBzHdxiE8IaSPCHEZU2ID8Sec02oblPxHQohvKAkTwhxeiz7V2u9Uanp/m8vsRBzhociOkAKjd6IK9/ej2NlrXyESAgvKMkTQpwey3HIr5VDZ2AR6utp8hhPDyHEQgGu+7/DeOzb03aOkBB+UJInhDg9kVCAjEgZxKL+P9ISgrvWyv+YXQMjS2P1xPXRlFNCiNNr6dBCrTciUuYFgYDp87hnFqXjHwtTUdzYAY7jUNWqRkyg1I6RElswGFmIhNRmNYWSPCHE6cnVeuwsaEBpUydeunZUn8fJvDwg8/JAuMwTh0tacMNHR5AU6oM5qSGYkhiEQG8JxsT42y9wMiT7i5rw5dFKVLWpsPneaQP25LgjSvKEEKc3LMQHd8+yrGztr/n1AIDixg4UN3bgo/1luDQjHB8sH2eLEIkNGFgOSaE+0BlYeAhN9+A0d2gR7COxc2SOg5I8IcTttHbq8G1WVa/ng33FPERDBmtOaijmpIb2e8zGQ+V46JIUCPsZxnFl1LdBCHE7b/xeiE6dsdfz352ohtrE88R5XTk60m0TPEBJnhDipIwsh5KmDosr2p2oaMXnRypMvqbRsyioU1gjPGJlnx+pQHlzp8XvSwnztUE0zoOSPCHEKXEcByPLwZKVcBzH4bmtBejre0FCsDcCpB7WCZBYTWGDEs/8mIc3dxXxHYrToTF5QohTEgkFFrfSdp9rRE61vM/XX7pmFIaF0L7zjiY+yBtn/30pxFZcJteo0EAm9YBEJLTaOR0RteQJIU6puLHD4vdsOt57st2FImSmq+URfolFAkhEQjCMdcbWmzu0+Pp4FTo0rr8FMSV5QohTig+yrIiNQqPH/qLmfo/ZcKh8CBERZxHsI8GD85IR5AZL6yjJE0KckqUVzracqoFqgJnzm09WQ6nRDyUsQhwKJXlCiFOydFa9OYe3qfTI7WfMnjgfuUqPh74+hUaFZuCDXRAleUKIwzOyHAxGtsdzTUqtRec4UNyM4eG+kIr7n2h148dHsbOgweIYiWP65GAZduTV41BJC9+h8IJm1xNCHF5XMZOek65C/SybJPfG9WPgLRGhTq7Gh/tK8dmh8j6X3w30RYA4j5QwX3x112SMjQ3gOxReUEueEOIWvCVdbZoImReeXZSBnDUL8Y+FqSaPLWpQ2jM0YiGDkYXWYERzhxa/5df3O4/iilERbpvgAWrJE0LclI9EhB159b2ejwn0wrXjY3iIiJijSanFQ1+f6u5+f+SSFCzICOc5KsdFSZ4Q4hYUGj38PHtWs/vm7ikoalTi//aVoqBWgbLmTqyakwQfCX00OqrNJ6u7E/yD85Lx4LwkniNybPSbTAhxSkaWg4Flza5Y5i3u/XHnJRZiVLQ/3r1xLDR6I05WtGFqUrC1QyVWpNb/tQzykrRQqxXIUWr08PV0vZLGlOQJIU5JKGAgFJg/QW6gncg8PYSU4J1AcWMH3r9pLEbH+FutQqFcpcf1Hx5GXJAUb92Q6VKlbmniHSGEEKdx46RYXDYyApH+Xma34nOq21HdpurzdZnUA5vumgKOAz7eX2atUB0Cw1laUcLBKBQKyGQyyOVy+Pn58R0OIYQQB8OyHASD3FNeb2Tx1A95kEqEqGvXICnUB4/1sSrDFoaa46i7nhDiVDiOQ51cA6GAQYBUDLHIvA5JrcEIjuvqlr/YvsImiEUCTB4WZO1wiQMYbIIHAJGAwfa8OmgMLG6aFIslYyKtGJntUZInhDgVhmEQ6e8FAFDpDBCbOerY3zjrtKRg6C+oqFfVqkKAt5hm2RMwDIPhEX5YkB6GO2YM4zsci9GYPCHEaUlNzJgfDKGA6dHCL6hT4KfsWqucm9hedlU7ypo7bXb+u2YMw23TEmx2fluiJE8IIRc4UtKCr45V4JpxUXyHQszw3p5iXPXuQbA2nF52SXrYgKszHJVNk/zatWsxdepUSKVS+Pv7mzymsrISixYtgre3N4KDg/Hggw9Cp9PZMixCCOlTdKAXRkT6Q2zhVrbEvipbVPjhVDXe+aMYyyfHITHEh++QHJJNB5x0Oh2WLl2KKVOmYP369b1eNxqNuOKKKxASEoIDBw6gpaUFt9xyCziOw9tvv23L0AghxKToAKldZ0+TwTGwLDafrMGSMZH4+4IUvsNxWHZZQrdhwwY8/PDDaG9v7/H89u3bceWVV6KqqgqRkV0zFr/++mvceuutaGxsNGu5AC2hI4QQ4qqGmuN47Y86fPgwRowY0Z3gAWDhwoXQarU4ceKEyfdotVooFIoeP4QQQgjpjdckX19fj7CwsB7PBQQEQCwWo76+9+5QALBu3TrIZLLun5gY2i2KEHel1hlR1aqCk9f0IjbCsvR7YXGSX7NmDRiG6fcnKyvL7POZKkvIcVyf5QpXr14NuVze/VNVVWXp/wIhxAW0deow5cVdmPXyblz+1gEU0h7w5CLXf3gYZ+vdu7fX4ol3q1atwrJly/o9Jj4+3qxzhYeH4+jRoz2ea2trg16v79XCP08ikUAikZh1fkKI62jp0EKu1mPYn7OoA7zFWLMoA9+frMa9sxOREOzNc4TEURwqbsbIaBnWLM5wyZ3lLGFxkg8ODkZwsHV2apoyZQrWrl2Luro6REREAAB+++03SCQSjBs3zirXIIS4hiAfCSpaVdAbWXj8ubztqswoXJXJ33p2juOgM7IQCQROu47amXAch3qFBgFSscnyxOfFB3tDa2CRESmzY3SOyaZL6CorK9Ha2orKykoYjUZkZ2cDAJKSkuDj44MFCxYgPT0dy5cvx8svv4zW1lY89thjuPPOO2mmPCGkFyPLQWil/cOt4b7/ncTOggYAwPNLRuDGSbE8R+TavjpWhX9tyUWEnyf2PT4Hoj5qGZwve0xsvITu1ltvxWeffdbr+d27d2P27NkAur4I3Hffffjjjz/g5eWFG2+8Ea+88orZXfK0hI4QwpcvjlTgqS15uHFSLJ5dlO5S+5A7otKmDjAMg/ggqdnbzO4+24g5w0NtHJntDDXH0VazhBAySHoji6+PV+GmibFD2umM2M5Pp2uxeLR9do7TGoz46mglbrVinXunXidPCCHOzEMowPLJcZTgHdi4uACcq7fNyovSpg7I1frux6/9VoiP9pfB6EBL92gfRUIIIS4r3M8Tai+jTc6t1BhwsLgZy6fEAwCWjo/BfAfbzIZa8oQQp6PWGXHHZ1lY9uFhtHXShlakb0IBAx+JCHk1clz25n5sPW29LYRHRcvwt7HR3Y+TQn0wPj7Qaue3BmrJE0KcjpdYiNunJ8BbIoTMy73XQRPzjIiSIcrfE3//5jRKmjpwzdhoxARKh3ROhmHgLfkrjeZUtyNC5oUQX8ep5UIteUKIU5qSGIRR0f40Hk7M9vK1o/HdvVOg0hmx51yj1c8vFDA4WNxs9fMOBbXkCSGE8CavRo4wP0+zWr9ylR5n6hUoalDiugkxFi9ZDPAWI8BbjFHR/oOMtrfmDi08BALIpB7IiJQ5XAEeaskTQlxaVasKf5xt4DsM0oeSpg5c/3+HodEPPDnu2Z/ysOzDI3j6x3x0am0zmc5SQobBPV+Y3jXVEVCSJ4S4tPxaBeKDqK69o1o8OhKxQVK8vrNwwGMvbIE3KDQ2jMp8P+fUoqVTa9aXFD5Qdz0hxKVdOiK839e1BiNVquMRwzBYOS0BAjMq2N02LR77ipqw51wTtufWIS2C/wJoyybGIsRXgg6tod96+nyhljwhxGnYYrncZ4fKbVYshZhnZkoIpicPvPEZwzC4dWo8APQoQsMnD6EAl46IQLCP48yovxAleUKI0/hofynUOoPl79tXiv8drTD52l0zE1EnVw81NGIns1JCsGJKXI+la6RvVLueEOLS/m9vCdZtP4slYyLx5rJMk8c0d2gdtiXmrHKq2zEiUta9xFGlM6BdpYeAYcByHO0UZ6ah5jj6KkQIcVknKtrw0o6zAIAg776TOCV467t4mdo3x6uwZmsBAEDAACeemo8AbzHkKj1OV7dj0rBAp54bwbKcQ9ZsoCRPCHFZte1qLBodCY3eiEBvqozHp6LGDgBAbKAU146Lxvku5IrWThwsbsa0pIHH5B2Z1sDC00Ng9ha49kLd9YQQl2dkOTQptQiXefIdisuqbFEhNqj/MrHlzZ0I8hHD17P/L1wavRGbjldh8rAgpIb7WjNMp0NbzRJCyEUunoUvFDCU4G1Ib2Sx+occqHX9rxWPD/YeMMEDQEWLCmu3ncF7e4rh5O1Q3lGSJ4S4FIVGj9mv7MGBIseqIe7Knv0pH3fOGAYvsXXG1FPDffHWDZnYV9iEo2WtVjmnu6LuekKIy+nQGuBDS6zsQqM3oqJFZZNu9eYOLbzFIqt9eRiKogYlogOkdo+FuusJIeQilOAHp1NrwHcnqnGopNns3dQ8PYQDJvgdefWD6nYP9pE4RILnOA73f3kSJU0dfIdiMfpLIISQIapuUyE6YGh7k/Nt15kG/POHXDQotACAYB8xjqyeB5FwaG3B7Kp23Pu/E1h39UgsmxhrjVDtjmEYaPSsQ3zhsBS15AkhZIj2FTaDZZ165BPlLSq0duqQEuaDj1aMx+Z7pw05wQPAe7uLwXHAzoIGh93ExRweQgbFjdSSJ4QQt3PjJOdsoV5o2YQYTE0MwrAQb6sWpZmYEIiV0xMwMT7QIYvFmEOjN6JdpYe32PlSJrXkCSGEwFsiQlqEn9Wrzt0xYxgmDwtyigRf1tyJOz7LwqGS5h69DsWNHZiWFGzWJjqOhmbXE0IIcSt6IwsPoQAGIwuhgIHWwOJERRue3pKH0uZOAEBahB/eu2ksEoK9wbIcOHTVW7A3ql1PCCF2Ut7cifhgb77DIEO05VQNXv71HORqPRKCvVEn1/TauvZMnQL3/+8kfrh/qlPX1KfuekIIucDXxyrxt/cO4sGvTiG7qr37+Z9zarF6c67TT7AjXZX3GpVaaA0sztYrTe5NH+YnwTs3Zjp1ggcoyRNCSA+LRkfCyAE/na6FzOuvEqy+nh5YPCbSKcaWSf8mxAciPaL/ru8nLxuOYSE+dorIdijJE0LIBbwlItw8KRYhvhIYL2i1z0oJwQ0XrfOWq/Xo1BrwxZEK6I2svUMdEo7jYHCymK1pZJTM5PNB3mJ8eeckXJ0ZbeeIbIPG5AkhDonjODR1aCEVi+xewc7PywM/3Dd1wAI3HVoDbv74KMqaO1FQp8CtU+OREubYu6a1dGjx3p4SHC5pwbXjorFyegLfIfFCLOpq4yaGeEOpMaBR2VUE6LGFqZia6Hyz6PtCSZ4Q4pAOl7Zg+fpjGBvrj2/unmLXfboXZoSbdVyUvxdmJgejrLkTXx6txFfHKnHgibmI8veycYSWKWvuxNfHK1FQq8ChkpbuHoogHzHPkfHnntmJOFzagvLmDqRHyBAbKMWCjDDMSQ3lOzSroiRPCHFIO/LqYWQ5HC9vQ4fWYNYWpbam0OghFgogFgq6x+avyozC9ydrAACZsf4Ol+DP23ioAiOi/hqHfu+msbhshHlfZgajQ2uA0chBJuX/382U42WtMLIcHpmfihVT4hzi98sWaJ08IcQhtat0WPrBYdwzKxFXZUYNao0yx3FW7QHYc64RGw9XwF/qgdeuG9P9PMtyYDkOCo0BAVIPNHVoEerrWPvX17SrEeXvBZ2BRW272qZLAc/VK/Hk5hycrmrH9OQQXDM2CotHR9q1N2YgXx+rRGq4LzJjA/gOpV9DzXGU5AkhDotluUHPZj9R0YpjZW24d3ailaMCdAa2e0z3vOLGDqzenINQX09sy63DymkJeGZRutWv7eg2Ha/EU1vyoDf2TC1XjorAOzeO5Skq27H2F8mLUTEc4pCMLMdLdSjiWoayXK1dpcfK6fHWC+YCFyd4AIgO8EJJUycKGzrwwc1jMS8tzCbXdmTHylrxzI/5vRI8AJysaOMhIutq7dQhQOoBpdYAqYcQa7bmIz7IG7dNS3DYzztK8sSq5Go9nvw+Bw0KDTbePon29Sa8GUqS3ZFXj3CZJ8bE+Jv9Hk8PIX57ZCbEIgH8XHR8tz8lTR247dNj0Bp6L8ubkRyM5xZn8BCVdWzLqUOdXI2NhyugNRjR0qGDl1iI6AApRkX5g+U4CEFJnrggjuPQqTN2J/ODxc3Yc64J394zhRI84cX5EcjBdqE2KjV4+48i+Es98PGKCRbtIR7sIxnUNV1BTIAUn9w6Ad9kVeP7k9Xdz89KCcGG2yY41Hi8udQ6I+oVGvx+pgE/nKoBwwCRMi9E+nth8ehIPDo/xeGLI9GnMBmS09VyPPl9Dn64bxq8xEKE+UnwwtUjMaKPQhOE2JpGz0JrMMJfavnysJ9zavHoptPQGVmIBAw2Ha/ErdPccx25pcQiASYNC8K4uACUNnegpLEDzy7KwBWjIpwywQOARCRAsI8YS8dFY+7wUIyO9kdMoJdT/f9QkidDkhTqgznDQ1He0om0CD8khfqaHI8jxF68xEKLWt8X+vRgOVLDfTErJQRXZUYiKfSvwjaVLSoE+4ohtcKe4ud3QXNFIqEAT12RBgAYFxfIczRDIxAw8PX0wNQk5y2OQ7PrCSFuo6hBid3nGnHXzN4z7ls6tMirVWB6UrDJSVTfZFUhJczXonF6Z7bpeCWuGRsNkYt+GXEWQ81x9K9HXEZutRxXv3cQ//j2NN+hEJ40KjU4Xt7a5+vhMk+k9bExSZCPBLNSQsBxHJo7tL1ev258jNsk+HaVDk9tycO+oia+QyFDREmeuIyR0TIMD/fF4dIWkx/SxPV9d6Ianx0q7/N1X08PzEgO6fcc23Lr8OyP+XDyTs4h6dAawDAMkkMduw4/GRiNyROXIhIIUN2mxtxX9uC168bgknT3W6vszu6bnQS5qvfe4JYYGxuAiQmBTjW5ytqiA6Q48PgcSF14hYxCo8cnB8oQHSDFzORghPo5VoVCa3Hdf0HillLDu1oeCo0Bh0paKMm7oaHWSo8J7H/nOWtq7tDaddnd+cR2qLgFjy5IweRhQX0e66pJ77ynfsjDT6drux/fPWsYVl+WxmNEtkFJnriURaMjERXgBYVaj5KmTnRoDbRenzgsiYnKebbkKxGhrLkTx8pbUSdX2/XajkSu0iPQW4xgHzGaO3R48rLhmO7EM+j7Q59+xKXIvDxcbqtI4hi0BiNYFoNenmeKvXc+YxgGXh5CTIwPdLgNdOxJJvXAmsUZePrKdFS1qhAXJO01POMqpbkpyRNCiBkkooGTe71cg3CZbZMnx3E4VNKCaYNseb54zSgrR+S8hAKmx258Ne1qNCg08JGIsOrLk1j3t5FOv9afkjwhhFhBXo0cpc2dWDw60qbXYRhm0Ame9O/5rfn4Nb8B3mIhHpmfgugA+83PsBVK8sSmlBo9fCQis2cqn61XwM/TA5H+XjaOjBDrGhEls2o55x159dh6uhb3zErEyGgqE20P/7o8HUE+EjyxcPiQJ3A6ClonT2zK19PDoqVIDBi8+luhDSMixPFVtqjw8KZT2JZbh2s/OIRvsqrcet2+vcQGSfHC1SNdJsEDlOSJg0kN98UtU+P4DoMQ3uiNLF7//a8vuloDi08PlsMVc7zByKJeruE7DJdGtesJIcQBafRGHCtrxb7CJoyLC8BlIyP4DslqOrQGvP1HEUJ9PbF2WwG+vHNyv2v23dlQcxyNyROLGIwshALG7C741k4dfsquQZ1cgycvG+7WVcQIsYSnhxAzU0IwM6X/MrzW9vWxSjR3aDE1KRganRGhfp5IDPG26t+uj0QEtc6ID/aW4K0bMjEh3rlnsDsy6q4nFvn9TANe3HEWcrV5pUP9PEVgOSCrog2bT9bYODrSlyalFvm1cr7DcElG1qk7Q3tZNjEWM1NC8Gt+Pd7dU4xtOXU2+XL+z8vTcPfMYbhyVKRLrEd3VNRdT+yG4zhqyfNk+fqjeGxBKka7yS5qQ1XW3Ilvs6owaVgQ0iP8EOLbd+nZp7bkoq1Tj9ExMoyK9qduZwu4SsEZW6KtZonTYBgGOwsa0K7S8R2KW2FZDmfqlPDzcp0Zw4NV1arq93WW5bDhYBnmvroH7+0pwS2fHMPcV/agQaHpfv/ewp7br/5jwXBkV7Xjp9O1KG3qtFnsroiPBF/YoLT7NflESZ7YTXGjEv/6IRetnZTk7elQSQs6tHoESsV8h8K7gfotfytowJqtBT2OU2oN+NcPeQCA6AAvhPpKoNYZu1+XST3w+6Oz8PMDM7BsQowtwiZW9O+fC2AwsnyHYTeU5IlVNSo0aFKa3sv955w6NCq1uPaDwyhvphaPvVS0duLjFRPg40nzbGOD+q9gtjAjDG8uG2Pila6szzAM0iL8etWvP/9YQF3PDu/TWydAJHSf1Ed/9cRq9EYWd27Mwpk6JaIDvfDSNaN6zJpdNiEWh0paMDE+EP4uVGzC0d00yXnrDqh1RjzxfQ4enZ/So8a4rTAMg8WjI5FXI0edXINTle2oaVebVbfe1dTLNThTp8CkYYGQil0nVbhTggcoyRMr8hAKkBjqg9PVcpQ2dWJ7bn2PJB8u88R7N4216/7ZxHkVNSjx4NfZOFOnQGq4L+6fk2SX6zIMg39dkQ6g60vG9yerERXgfmWWj5S24OFN2bh3diKeuHR4j9cMRtbtkqWzoiRPrCrIu2vcd1xcAO6ZNazX65Tgibke3tSV4EdGybB0fDQvMXiJhbh5svP2hAxFXo0cAVIPXDM2CjoDi7LmTqSG+wJwv9awM7Ppv9TatWsxdepUSKVS+Pv793r99OnTuOGGGxATEwMvLy+kpaXhzTfftGVIxMamJgVj+eQ4fHXnZIT6Oed+1bnVcrSrdNAZ3GdyjiP67p6peO+msXjvprFuvfc5X1LDfXHwyblICvXF0v87jH0XrSogzsGmLXmdToelS5diypQpWL9+fa/XT5w4gZCQEHzxxReIiYnBoUOHcNddd0EoFGLVqlW2DI3YyJzUUMxJDeU7jEHTG1k8+1MeTlW1Q8AwuDozCn9fkIIImft11/LNSyzE5QOUcqXaC7azdPxfKwVmJQfjpsmxPEZDBssuxXA2bNiAhx9+GO3t7QMee//99+PMmTP4448/zDo3FcMh1iRX6TF53S6o9X8tkRIJGCzICMOaxRnUonQAewubECD1QEakDOfqlUiPpL974rpcrna9XC5HYGDfdYy1Wi202r+WaCkUCnuERdyETOqBhy9JxrrtZ7ufEwkZjIr2R5A3zSdwBMmhPnhkUzYi/b3wytLRNr1WS4cWP5yqQYfWgJgAKa7OjKJlcsSpOFSSP3z4ML755hts27atz2PWrVuH5557zo5REXezcnoCduTX41RlOwDg/ZvHOfUQhKuJ9PfCprun2OVar+0sxP+OVgIAlk+Ow5IxkRCAkjxxHhZPvFuzZg0Yhun3Jysry+JA8vPzsWTJEjzzzDOYP39+n8etXr0acrm8+6eqqsriaxHn9XtBA17+9ezABw6Bh1CAGyfGQiwS4IWrR2JWsn13ASP8U2j0KG7swKbjVXji0uH4/t4peH5JhlvNKne38q+uyuKW/KpVq7Bs2bJ+j4mPj7fonAUFBZg7dy7uvPNOPPXUU/0eK5FIIJFQt6m7enNXEXJr5FiYEY5R0f42u87CEeEoqFPgxkk02cgdlTV1YuWG44gNlOLe2Yl8h2N3R0pb0NapQ0qYL9+hkCGyOMkHBwcjODjYagHk5+dj7ty5uOWWW7B27VqrnZe4Hr2R7R4P3XCoHK9dN8Zm1/Lz9OhVAIS4j9Ex/jjxdN89iq6OdtJzHTbte6qsrER2djYqKythNBqRnZ2N7OxsdHR0AOhK8HPmzMH8+fPx6KOPor6+HvX19WhqovWYpDcPoQBf3jEJs1JCsPlkDR7ZlA3NBbPgzdGk1OLpLXk4Wz/whE1PD/crZUoIcS02XUJ366234rPPPuv1/O7duzF79mysWbPG5CS6uLg4lJeXm3UNWkLnfgxGFvd/eRK/5jcgM9Yfm++datFa6UalBv5eYohFzjG+qtEbodYZEeBNu8jxobVTB38vD7vOqj9Xr4TWYLTpkBRxDg69n/yGDRvAcVyvn9mzZwPomsRn6nVzEzxxTyKhAP+6PB0T4wNxqrId352otuj9ob6evCd4pUZv1nHFjR1Y+MY+XPn2Adqilye17WpMWPs7ntuaD72dtigtbFDirV3FsEMZE+LinKMpQ8hFYoOk2HT3ZNw6NR4v7TiH4kbnmgns5SE0a09rmZcHrs6MAsdx+C2/3g6RkYuNiJJhy/3TcM3YaHjYaXZ9TKAUQd5iquZHhoySPHFaDMNgWlIwmju0+HBfKd/hDEhnYPH0ljxwHIftefV44vtcNCo1/b4nxFeCVXOSMCbWH1dlRtkpUnKxmEApRkTJ7Ha9MTH+eOnaUQMep9EbUdSgRFWryg5REWfkUMVwiHNjWQ5rtuZjfnoYZthpbfmM5GAsSA+DXG1e9zefxCIBDCyLI6WtWDQ6EotGR5r1PpFQgPduGmfj6Igz2nCoHC9uPwuGAZZNiMELV4+k1j/pwS61622JJt45jk6tARnP/goAePrKdNw+PcEu1zWyHORqPQKdZGKakeUgpNKoxApYlsP7e0sQ7ueJ5g4t7pgxjH63XIzL1a4nzksqFmLbg9NxoKgZnVqD3a4rFDBOk+AB8P4hzHEcsiraMDY2YFCxtKt0KG9RYUyMP4CuYQi+JzK6K4GAwf1zkvgOgzgw+sskVsMwDDIiZbh7ViIenJfMdzikD+UtKiz94DBKmjoG9X5/qbg7wQPAV8cq7fqljhBiPkryhLgZvZFFqK8E23LqzDpeZ+h/FcAtU+PhLXHNTkFzVkA4K5Z16pFaYiZK8oS4mZQwX+x7fA5unRo/4LFytR4rNxzHxkPlMBhZ7C1swk+na20fJM+MLIcfTlVj8TsH7bY23p7aVTrMeXUPXv71LPJq5HyHQ2yIkjwhFvjmeBUOFDXzHcaQeXoIzaqgZ2Q5KDV6HC1rxabjVcirkePtXUUwGFl8uK+k+ziO41DcOLju/+YO7aDeZ0tCAYMwP088uyjdbmvj7clfKsYjl6Tg3d0l0BosKw1NnIvr/fYSYkMzUoLhJXafP5sAqQc23T0Ffl4eOFXVhpd/PYcbJ8VCwDDIKm/rHouvbFXhl9w6aA3GAbv3L+bv5WGL0IdsamIwJrnwRi1XZUZhXFwA4oO8+Q6F2JBrDqQRYgMcxyFC5oUImRffodgNwzDw9BAiLkgKtc6IUF8Jrp8QA4GAwdLxMd1d2WF+nrhvdiLe31OCb09UY2S0DMsmxJhVL4HWdfPnX1ekIciHtu52ZZTkCTHT678XYWJ8IKYnW2+rZWdxz6xEKDR63D1rGKTiro+N+elh3a+f37FPodGjSalFdIAXpphoBbd26iBgurqLz8uuakO7So95aWG9jie2NTY2gO8QiI1RMRxCLGAwshC54Bittfxe0IDJiUHwMXO2/b7CJtz1eRaMLIfcNQtpe19CLkLFcAixI3dO8OZ8wbkk3bLW+OaT1dDoWcxKCYGECuoQYnX0V0UIGZDeyOLx73IGPK5errFoydmL14zC1MQgvHvTWBqbJ8QGKMkTwgON3oiP95eius05dg/zEArw6nWjBzzu4/2lWH+grNfz9XINfs7pvb7e00OIjSsnmt29TwixDCV5QuysuUOL2z49jv9sO4MVnxxDnVzNd0hmMaelffPkOMxJDe3xnN7IYkt2DQ4Wm64vIBIK0KjQYMupGqvESQj5C028I8SOWJbDFW8fwJk6Rfdzo2P88eP903iMyj44jjP5RaGkqQMr1h9DbKAUn942gSbfEXKBoeY4askTYkcCAYOv7pyESy5YLjY9yXULrlyor56AhCBvfHvPFErwhNgAJXlC7MxfKsZHK8bhhatHgmGATw+Ww8k71Pp0rl45YAW8OoUG2VXtTjM/gRBnQkmeEB4wDIMbJ8VixeQ4qHRG7D7XyHdINvHDqRqs+ORon6/vL2rC9Jf+wH3/O4nTVbRRir0YWc7kLnQXftnkOA6tnTp7hkVsgMbkCeGR1mDEvsJmJARLkRTqy3c4Vteg0KC6TY1xcaYrq7Esh+KmDrzzRzFevW60S24G44je3V2MX3Lr8Oj8FMwdHgqGYbC/qAlv7yrGR7eMx2/59dh1prFrT4KHZvAdrlujYjiEODGJSNijPKwr+CarCiMiZUiP9EOYnyfC/Dz7PFYgYJAS5otz9Upo9EZK8nbQtY1uDYobO3D7Z1m4JC0MUf6e+PJYJfRGDtNf+gNKTdfGQ9eOi+Y5WjJUlOQJcVEcx4HlurZNtSWN3thjwty4uABUtqiQHmleq4PjODx8STJ8PR1zNzpXIxQwSArx6d4a+PczDT1eP5/gAWCyC+/C5y7oazMhLqZdpcNrOwsx79W9KGxQ9nusSmdAc4cWJypase6XM4O63sUz4hNDfDC2j+55UxiGwWUjI7ofG1kOu840WFQ5j1hmQkKgWcf5SGi1g7OjljwhLmbr6Vq8tasIAHC0tAVpEb1b1BzH4b+/nsPvBQ0obupAuJ8n/r1khL1DBdBVLOfCbnojy2H9gTIkhfogjvY6twlz9wmYmTLwVsHEsVFLnhAXU9Ou6f7vHfn10BqMvY7R6I04VNyMAKkHFqSF4b/XjrJ4c5n+yLx6d73/kluHRoWm1/MXj8OLRQI8vyQDsYHSfq9hNDE7nJjnXH3/PTznFTV02DgSYmvUkifExdw8ORahvhIUNSpx8+Q4MOg9Jl/Vpsbp6q4law/OS8aMZOu32MqaO6HU6DEq2h8AUN2mwmUjws1678UrDVo7dVDpDIgO6Er87SodKlpUGBUto41tLKTQ6KHU6BHiK0GTUtvrdYYBUsN8ER0gRXKYDw8REmuiJXSEuCGO43C0rBXZVe14cftZvHfTWFx+wbi4NeiNLDq1BvhLxYN6/8nKNnBc10Q+pUYPg5FDgHfXuX7MroG/lxhTk4JoRv4gcRyHf/6Qi6+OVfV4/r/XjsJ142N4iopcbKg5jpK8nRlZDvm18u7WDZ9u/fQYztQpIGAYCBgGDAOkRfjhw+XjqHXkJjR6IxoUGhhZDsNC+G+1GVkOTUotwmV9L7sDgCOlLRgVLYNUTJ2RQ6EzsBj/n51Q/DmjftHoSLy1bAz9/TsQWifvZOrkajR39OwiK25UIsTHEzKp/ZYQnahow55zTb2ef3XpaPoDdyOeHkKHmtwmV+txoLi5x/psluWg1Bp6jPOfX9pV2KAEy3EYHu74X/AdkVgkwJs3ZOJUZTui/b0wLTmY/v5dDCV5O4sOkCLIW4Jz9UqkhvtCrTMiv1aBJWPsV+3MYGTx9Ja8Xs8LGMBAk5lspqKlEw0KLXKq27FyWgIENl6/bmscx+GrY1UwsiyWT4m3yjkDvcW9CrD884dcqPVGvLkss8fzeiOLf3x7GvPSwijJD8Gc1NBe2wMT10FJngcSkQDhf1YB8xILsWRMlF2v/8HeEhRcsNUpAKSE+eC168ZgRJTMrrEMxicHynDbtPgeLY7KFhVig/qfjc2HgloFfj/TgGNlrThY0ozzg2NBPmJcnenc1cQ+3FeKddvP4t9XDW3pHctyJr/wlDV3IjbACwnB3iaXcv2cU4vP75iEunb1kK5PiCujJM8DgYCxa9f8xRoUfw0XeIuFeHRBKm6ZEgeRk0xgaurQorxFhYTgrm5mjuPwwb4SvHD1SJ4j6+35n/NxpLS11/P/O1KJ2Smh3RPJnM11/3cYJyraECHzxJIxkUM6V189Gut+OYPFYyJx96xEk69fmhEBL7EQwgDn7hEhxJac41Od9KDRG5FXM/gdu66f0DVzNsrfCxtvn4Tbpyc4TYIHgMcXpqKs+a/1uwzDYNWcJJtcK79Wjt/y6wFgUNvBvnTNKHgIeyehrIo23Pe/k9Doe69hdwZChsH3907F3n/MgZ+NytHeNycJs/vpRvYSd1Vj85ZQW4WQvjjPJzvp5ukhxLM/5eP+L0+itMnyYhUZkX64eXIsflw1rc/dwRyZWm/sNVks0t/L6tdpV+nw9JY8/N++UrAsh+e2FlhcgOXNXUXQG02/53BpC9ZuG1wpWb7NTw/DmBh/iC+qnCZX6dHSoUV5cye2nKqx+H7tOdfYPTF1TIw/fCiBEzIklOQdFMdx+PJoZZ+1x68fH4NtOXWY//o+rN6ci3p570pifWEYBv+5aiSCfSTWCreXoVQj25FXj7Z+9rGWikVItMNyry+OVOBkZTtOVLThuxPVePzSVIs3e6lr7//f5fMjFXjiuxyodc7Vol85PcHk8wIBcO//TuLpH/Pw1q4iPPjVKVS3qcw65x9nG/DoN6dNFmi5kIFq2hNiNkryDkiu0uO+/53Ec1vz+6wxfeXoCPhIRDCyHL46Von5r+2FXK23c6S9tat0eHH7WUxZt2vAzVH6kh7hh605tVaOzHLXTYjBw5ckQ8AAC0eED2pN9qVmVHjblFWFZR8dGdIQjKPw9fTANWOjcN34GPzx2Gy8e9PY7ip1A5maGIyH5iUjvp8lfRzH4beChj5fJ4T0REneAXmJhahqU+GGibF9rmGWikVYNDoSHkIGd0xPwIaVE03WC99f1NRvq9halBo93tpVhBkv7cYHe0vQqNTi9s+Oo7jRdKJ/fWchTlS0mXwtNkiKFVZakjUUob6eXXttB3iZvLfmWDYxBikDlAb929gozE8LRVZ566DG/R3N9RNisWi05ZPxPD2EuGVqfPdYuykMw1i9Mh8hrowGvByQWCSAj0SEOcP7X7v69wUpuHZcFMbF9d42sqVDizd+L8LnRyrg6ynC3+en4ObJtptB//YfxfhwX2mP56pa1fjkYLnJWe9XZUbhZEUbRkXLHLosqVQsRHWbGv/+uQBPX5lu8fslIiHeXJaJOz7LQs2fS72CvMW4OjMKSaE+SAz1wfi4ACpAcgGO43C2XolhId6QiGirU0KGgsraOqgfTlWjQ2vEtMQgs8uNchyHJ77Pwa/5DSa77lPCfPDsogxMSwq2drg4UdGGpR8cwi1T47FyWgJCfP8a7794v3Fn88IvZzA1Majfmd4D+fxwOQ4UN+O2aQlIj/Sz2Yx0V7D1dC1ya+T45+VpfIdCCO+odr2LJnmga6lcZWsnYgK8++3CBLqqf736WyE+2FvS73FPXDoc9842ve54qHKq2x2iJr81qHVGvLTjLJo6tPjHglTEBw+t9CvLcmAYUIvdDBq9EQqNHqG+puvXaw1GauETt0G1611MXo0cP52uxa4zDShp6gQA3DAxBuv+NqrP9+wtbMLabQUo7GfvZ5mXB+6dnYi7Zw6zesznuUqCB7rmRYT5eWLDoXLMSgkZcpJ39hK29qIzsPD0EPbb+/NLbp3JaoF6IwuDkRvwCzEh7oSSvAP5/HA5nv4xHwDgIxFhamIQkkN9cOOkuH7flxHph1Bfzz6T/IzkYLx4zShE2WAt+Xkcx3W3UqtaVQjxlTh9N/29sxOhM7DYV9hEW2/a0IaDZciuasfTV6YjaIBlnUaW67Mc8Evbz0KpMeCla/v+QkyIu6Ek70C0BhaxgVLcMjUe10+IMbsQSLCPBBtXTsTyT47iYHFLj9dmJAdj48qJNu8mvvD8MYF/LZnacqoGoX4STE20/jwAe3jokmScuajOPxnYhV/6BvLlsUoUNnRg+ZT4AZP854fL0a7W4+FLUno8X9SgxIZD5TByHG6dFo+0CNcauiNksBx3WrMbum5CDPb+YzZun55gcaUvgYDBF7dPQnTAX611DyGDfyxM5XUcOKuiFRsPVfB2fWughGGe3Wcb8cmBMpQ1d+L3M41mv2/JmCiMiwtAWVMHPj9c3m+9gPRIWfeeBRcqbuyASMiA47omSjr5VCNCrIZa8g5kqDOu9xY2QW9kwTBAWrgfrsqM5H2c/N9LRqDWgmp8xHn9e1sBSps68frOQswZHoq5w0MhFDA4UdGKTq3R5E5yAHD/nCT8mF2DddvPok2lQ3yQN3Y8PLNXyVwAmJjQe7koAExPDoaR5RDsI8Yj81NgZDmITOwZQIi7oSTvQmanhuLI6nlQ642Dqs5mTS0dWmzPq8eiUZE2nQtAHENliwoVLSpckhaKeWlhmJQQ2F0C+Ehpa48eJlMenZ+KQ8XN+PJYJcbFBZhM8P3xkYiwID0cl40Mx9hY59uPgRBboSTvYhiG4T3BA4CAYboqxfG4pa4ttKt0+N/RSsxPD0NKmC/f4TiMdrUOH68Yj5kpIb3q+99vxg6Bl44Ix5RhQdh4pGJQ95VhGLx701iL30eIq6MxeQfjSFuPFjYo8fdvTuNQcfOAxxpZrkf53ABvMeYMoXiMo3ro62y8/Os5LHr7AL46Vmm367JD2PDHHkZF+2POn93zg+UhYvDEpcNx9dgoK0ZGiHvjv8lHAHStD35rVxHEIgEenJfMdzgAgKKGDnx/sho/na7Bp7dOxPRk0zPk9UYWAoZBq0qHAG+xnaO0r0BvMTw9BFg8OhJXjbFdMjKyHD49WIYGhQYnKtrQrtJjeIQv3rtpnM2uyTepWNSrUJOR5fD81nysWZxBhYQIGQRK8g6gtKkDj2zKxulqOaYMC3KYJN+o7JowpzdyePy70/jP1SMwJzW0x4dtW6cO6w+U4bGFqXbZ/pVvzy/JwHNLMmxWlra6TYUHvzqFRqUW1W3qHq852ix/I8sNqeVuDr2RxVKqUUDIoFF3vQMwsFz3HtonK9ugNThGl/2FxWxq5Rqs3JCFy97cj6rWv/YHD/AW47GFqXyEZ7GadjV2n2tEp9Yw6HP4enoMKcG3derQamJXwCOlLfjnD7m4a+MJnKxs75XgASDIx3F6SYwsh/v+d8Lm1/H0EGJElIxa8YQMErXkHUBKmC/+fdUI3P5ZFrQGFodLWoa0GYq1XLy96ugYf6xZlN6j2I0zYFkOP56uwcs7zqFWrsHi0ZF464ZMu8fRoTXgmvcPAQxwSVoYbpgYi62na3GwuBlHy1oHfH9BrcKiIjO2pDOwuGVqPN9hEEIGQEneQcxLC8PKaQn45GAZPj9c4RBJ3tez69dDKGDw9BVpWDEl3ulqsGsNRrz6W2H3NrixgVL8+6oRvMTyyYEylDZ37UfwYVNpr615B5JV0YbbNhzHC1ePRCTPyxK9xEKnrWJIiDuh7noHsnJ6PMQiAW6blsB3KAC6uqYZBvh4xXjcOi3BqRK8Rm/ER/tKMe/Vvd3JVCIS4P2bx/bqobCHtk4dPrIwqZuy51wTZr+yB1tP11ohKuciV+u754kQQsxDLXkHEh0gxe7HZjtM8ZiYAC/cNzsRc4bz36tgKU8PIa4ZF41gXzF+P9OIxBAf3DQpFmF+prcvtbUP9pVAOYS5ABfSGVi88MsZXD4ywuYT3xxJXo0cFS0q3Dgplu9QCHEatJ88IXZQ3KjE0g8Oo02lt9o5X79+NK4aE+UQY/T28mt+PRZmhPMdBiF2M9QcR931TorjOLSres/SJo4pKdQX3hZuOjSQRzadxt2fn8C5eqVVz+vIKMETYhnqrndS35+sQZCPa1aVc1XJoT4ml8aZK8RXgialFh5CBnfPTERmrD/mpYVZMULr4zgOx8vbsL+oCUdKW/DsogyMiJLxHRYhboOSvJMKkHrAaHTqkRa3otYZ4TeICX8MA9w4MRY3TopFYogPCuoUiJB5IkLmGPM2BrK3sAm3fnocQNfWx44y34QQd2HTJL927Vps27YN2dnZEIvFaG9v7/PYlpYWjB49GjU1NWhra4O/v78tQ3N6jt6CIz15iYWYMiwIP2YPPCteKhbi0oxwPDAvGREyT0hEgu5xd2fbYW16UjDW3zIeRpZDUqiPy5c9JsTR2DTJ63Q6LF26FFOmTMH69ev7Pfb222/HqFGjUFNTY8uQHEZbpw53bsyCnuUwPMwXt02Px/Bwmjjoyq4dF413dhf32WUvYIB7ZyfikUtSIBK6xnQZkVBAX0gJ4ZFNk/xzzz0HANiwYUO/x73//vtob2/HM888g+3bt9syJIext7AJWRVtAIDTVe3YlFWF164bjb+NjeY5MmItVa0qiEUCFNQpoNEZER0gxZzUEHx+pPfudX6eIryxbAzmDqeESAixHt7H5AsKCvD888/j6NGjKC0duFiIVquFVqvtfqxQKGwZns3k1ch7PF41JwlXZ9IWm66irLkTSz84jOYObY/npyQGmTz+wXnJlOAJIVbHa5LXarW44YYb8PLLLyM2NtasJL9u3bruHgJn9tSV6bhhUiwOlbQgOdQHk4eZ/vC3B63BCIlIOPCBZEAcx2Hd9rP4aH8p+qpA4S0WolP31yZEUrEQN0+Os1OEhBB3YvHA35o1a8AwTL8/WVlZZp1r9erVSEtLw80332z29VevXg25XN79U1VVZen/gsNIDPHB8slxvCT49QfKsOjtA7jszf24/38nIbdikRZ3drKyHR/uM53g5w0PxXs3jsUXd0xCaphv9/NXjIzoseMfIYRYi8UV75qbm9Hc3NzvMfHx8fD0/Kt86IYNG/Dwww/3ml0/ZswY5Obmds8c5jgOLMtCKBTiX//6l1ktdqp4Nzgsy2HN1nxsPFwBoGsN9he3T0JquO8A7yT9ee23c3jrj+Iez4kEDJ64dDjumJHQ/buuM7AY/vR2zB0einduHEtJnhBi0lBznMXd9cHBwQgOts7uU99//z3U6r9mGh8/fhwrV67E/v37kZiYaJVrENMEAga3To3HzoIG1Mk1aFJqUdbcSUl+iG6eEofJiUEoqFVAIhJAIhIiKcyn19I3DyGDU08vgK+nyKk2/iGEOBebjslXVlaitbUVlZWVMBqNyM7OBgAkJSXBx8enVyI/30OQlpZG6+TtYFiID/b8YzYe3XQa23LroDOyfIfk9EJ9PRHq6zngNqwMw0Amtf9ueIQQ92LTJP/MM8/gs88+636cmZkJANi9ezdmz55ty0sTM0lEQjx52XCcqVPgkwNlWDw6ku+QCCGEWAntQkcAdO3VXduuRloE3UNCCHEUtAudmzhV2YaHvj5ls/PLvDwowRNCiIuhJO8k6uQa/Jhdi06tge9QCCGEOAlK8k4iNdwXQgGDOvngtyolhBDiXijJOwGW5RDqK8H7N43FL7n1+CW3ju+QeLH7XCO2nKqB+oJqcYQQQvrGe+16MjCNwYg5r+yB1sBCqenqrt9831SMjQ2AzsDiVGUbJiYEdhdacUWdWgP+8W0Omju0eG5xBm6ZGs93SIQQ4vCoJe8EpGIRlo6P6U7wQd7i7v/+/UwDntyci/Y/y9JuPV2LdpWOt1ht5WBxM5o7tHjkkhRK8IQQYiZK8k7i8YWpeHR+CgAgwFuMmcldxVbigqT4aMV4BHiL8frOQjz49SkU1Dnnznz9GRPjj/W3jMd9c6gSIiGEmIu6650EwzB4cF4yJiYEYm9hEzgOYBggI1IGoKvuf3qkHxaNikRiiA/P0VpfqJ8n5vl5DnwgIYSQblQMx8lVtaoQEyi1yrk4jnPpcX1CCHE2VAzHzTV3aK12rs8OlePbLOfdupcQQkhPlOSdXOZFu5sNRVyQNzafrLHa+QghhPCLxuRJt1kpIUgOc73xfEIIcVeU5Ek3gYBBdIDl4/slTUq8+lshImRemJ4UjDnDQ20QHSGEEEtRd70LOV7eil/z6+1+3cQQX/z32tGYOzwUP5yqweaT1VDpqMY+IYTwjVryLqS0qQMv7TiHqYlB8PX0sOu1fSQiTEsKxtTEIJqhTwghDoKSvAtZOi4GE+ID7Z7gL2TvBP/vnwtwtl6B55eMcMn6AIQQMhTUXe9CBAIGw9ws0T10STKWjovBoZIWvkMhhBCHQ0meODU/Tw9cPjIC7Z2uV6+fEEKGipK8m2lUaHCsrNXs4zmOwy+5dbj6vYOY+8oe/F7QYMPoBkfAAPfNSeI7DEIIcTg0Ju9GGpUa/GfbGUQHeGFiQuCAxx8oasb9X56EXK3vfs7AsrYMEb/m12NSQiD8pWKz3yMS0ndVQggxhT4d3URVqwpXvXMQP52uhbfEvO9205OD8d9rR/V4LiHYtmP+pyrb8cpv5+DkWyoQQohDoCTvJmICpbh+QiwAoENr/hr26UnBkIqFAACJSID4YOtshtOXFVNicWlG+ICz9I0sh5s+PgK90bY9C4QQ4swoybuRUTEy+EpE6NCYn+S9JSK8uSwT3mIh3rtpLCQioUXXLG7ssOj4SH8ppieHDHicUMBg3vAwmNPg1xqMqG5TWRQHIYS4Atpq1gFpDUZodCzWHyhFXJA3rhkXbdVz17VrEB/sbfZ7OI5Dg0KLcJll+7k3KjW447Ms/LRquqVhDkpNuxpioQAhvpIezx8sbsZj357GtgdnINDb/LF+QgjhG20164J+L2jElBd34a0/ivHJwTI0KDRWO7dEJLQowQNdBW4sTfAAoFAbIPPqXZinpl2NB786Ba3BaPE5+xPkLYZG3/uc05KCcXj1PErwhBC3Q0meR01KLdpVvdd3Z0T6QaUzYnxcANo6dfD0sKyL3FEkhfrg89sn9Xhu6+lazH1lD34rqLe4K38gnh5CxATads4AIYQ4E1pCxxO9kcW7u4sR5C3GA/OSe7wW6e8FmZcHogK8sGJqvMnWsLPRGVh8fbwSr+8shNbA4uMV45ERKeM7LEIIcWmU5G3AYGRxuLQFM/qZQOYhFGDN4gyTr4lFAux8dCbAAcE+EpPHOJsNh8rwwi9nAQApYT64JD2M54gIIcT1UZK3gYc2ZaO6VYUJ8YG9utpr2tWI8vca8ByhvpaPgTuy82vzJSIB1v1t1ABHE0IIsQYak7eBJoUWzyxKxxdHKnq9dqzMOhupONuiiGAfCcbG+uPnB6ZjXFwA3+EQQohboCV0NqTRG202ae75rQV4ZlG6Tc5tC62dOgRIPWiveUIIsQAtoeMRx3FYf6AMB4ubTb7eV4If6vcqluUwLy10SOewt0BvMSV4QgixMxqTH6Rvs6qwJbsGB4tb4C/t2u70hatHmvXevYVNmJ06+CQtEDCYlhQ86PcTQghxD9SSH6QrR0UiJqBrTXa7So8vj1biw30lZr13KAneYGRhMKNe+1u7ipxu3J4QQoh1UZIfJC+xEP+5agQuSetaCuYtFiI13M+qifVERRtOVbb1eG5bbh225tT2+z69kcX3J6vxa75t937nOA5Z5ebvTU8IIcS+qLt+CERCAT5aMQ5n65Xw9RQhOsC61dZKmzogYBhkxv41G33JmKgBv0g8vCkb05OCMSJqaBMRWZaDWm+EVCw0OZ7+xPc5+Ol0LbKfWeC0VfkIIcSVUUt+iBiGQVqEn9UTPAAsHhOJqIDea+oHmsD2+nVjsPbqkUOO6dFvspHx7K/4cF+pydfnDg+DRs+iSakd0nUIIYTYBiV5ByYRCTF5WJDF7xOLhv7PqjUYsetMIwBA2cfWtOf3mW/p7F1/nxBCCP+ou56YxHHA04vScbqqHWF+vUvrag1GvLj9LLzFQiSF+vAQISGEkIFQkudBo0KDpg4tfsyuxd0zhyHIyvXpOY5Du0qPgCFsrerpIcR142Nw3fgYk6/vL2xGTbsa98xKhI+Efo0IIcQRUXc9D7bm1GHxOwfRqTWY3OO8vLkTOsPAy+RMMRhZPP5dDh779jQUGj1UOtNd7UM1KzUER/85r9cOeoQQQhwHlbXlSYNCgxAfCQSCnpPonv0xD9Vtany0Ynyv18ylN7KY9MIutHbqMCM5uNee7sT6atvVMLKcTfez1xlYfHygFCIBg/ggb0xPDoZUTL0ohLgyKmvrAKrbVBa/J8zP02QSTw33g1QiGnSCB7q2sZ2a2DVh79IR4YM+DzFPa6cOc1/dgxn/3Y3jNqwb0K7S4a1dRfjiSCX+8V0OPjlQZrNrEUJcAzUDhkiu1uPF7WcxJsYfBXUKPLc4A76eHoM+342TYnHjpNghx/W3sVGoalVhR149bpwYS3XjbaSytRP/+fkMNHoWCzPCMDbWdjvshfp54oaJsQj388Tt0xMgoH9TQsgAKMkPkczLA4tHR+Kuz08AAOYOD8WVoyJtdr2Klk54S0QIlIr7be3PHR6G2SmhqGlXQ2/kIBZRQrCFp7fkY29hE4CuXhPhEHpgzJEe4Yefc+pw96xEm16HEOIaKMkPkdZgxIs7znY/rpdrbHq9h77ORkVLJ4J9JPj5wemQiPquNCcQMDYdIyaA5M+aBBEyT7tcjwPwryvS7HItQojzoyQ/RBKREG8ty8TKDcftcr3lk+MwPyMMSo0B7OAm4BMremZROu6cOQzj4wLsMiTS15JGQggxhWbXOxC5So//HavAjRNj4S8d/Bp3QgghrmGoOY5a8nb0S24dYgKkGBkt6/F8Tbsa6/eX4evjlVDpjBgW7I1LR0TwFGWXqlYVBAIGUf69a+cTy3xxpALTkoKREOzNdyiEEDdDS+jsqKy5E1uya7ofa/RGPPz1Kcz87258crAMUrEIG26bwGuC1xlYvPF7IS59Yx86+qhZTyxzpLQF935xAgqNnu9QCCFuhpK8HZ2pU+BgcTPUOiMA4KfsWvySVw8jy0HAAL88NB2zU0PNOpdcpYdGb7RJnEWNHejUGRHia7rcrtZgxI68euwvahpw21sCsByHs/VKXPHWfptVICSEEFMoyduJSmeAgGHwytLR8Ppz97arMqOQGuYLAQO8eM0ohPr2nKF9qrINeuNfs+s4jsOj32Rj1su7Mfr53/BLbp3V4xSLBHj3xrE49fR8k8vBSpo6MPeVvbjnixNYvv4Yjpe3WT0GV/O3zGgAQFWrGt+fqOY5GkKIO6EkbydSsQhv3ZCJEVF/jcdvPFyO3Bo5BAyDb45X9WqZB/tI4CH865+IYRg8ODcZD85NxmcrJyIuSGqzlnSAtxgyr55FfVQ6A1ZuOI6adnX3c/uLmmxyfVcyLy0U6RFdE2a22eCLGSGE9IUm3vHoilERmJQQhFq5GsE+EuiMLDw9/lr3bmqNe3ywN+J5mMCl0hnwzI/5qGj5q4RvXJAUC9KpbO5AGIbBgowwaAxGDAvxAcdxVIGQEGIXtISODIjjODz4dTa2nq7tfu7umcOwam7SkEr4uhODkYWAYYa0JwEhxP3QBjXEpg6VNGPM8zt7JPgF6WF48rLhlOAtcKikBa/tLHTZiYrbcup6DOMQQhwDJXnSr6RQH6SE+XQ/9vQQYN3fRtqtu5llOXxyoAz/3XG2e1WCM/r9TAPe2V2MH07VDHywE2pUalDa1NHvMa2dOlpGSIidUZJ3AodKmnlrAYb6euL9m8dhelIwAOCStDAE+ZheWjdUSo0elS0qHC1twanKNvyaX49lHx7B8z8X4L09JVj6f4egdNIkcf7+vfpboc2WPvLptmkJmJEc0ufr5+qVmLD2d7y/p8SOURFCaOKdE5CKRahoUfEy4Q7omuX/6W0T8NauIpQ1d1r9/L/m1yO/VoEP9pZAZ+i7IH9ejQJPbcnDm8syrR6DLbEsB7XeiFumxGF+enj3pjYXalRqcOdnWejQGvC3sdEYFS1DS4cO89JCu4dFfsyuwcSEQETInK8K4bAQb/zz8jSkRfjyHQohboUm3rkIluXAASbXtuuNLLaerkV5iwpn6hSIDvDCs4syBnUduUoPmdR6Y/E/nKrGI5tOW/SePY/N5u0Lz2CwLGfWhLu7P89CTbsaWj0Llc6IWrkaGZF++O6eqfD0EOLV385BZ2Cx+nLahY4Qd+HQtevXrl2Lbdu2ITs7G2KxGO3t7SaP27BhA1577TUUFhbC398f1157Ld555x1bhuZyXv7tHOakhmJiQmCv17acqsE/vsvpfrxodOSgl3FZK8GzLIfHv8/Bd2YUh2EYIEAqRqC3GLGBUrR06pwqyZs7o/7/lo/v8fjnnFr8mt/Qvazy7wtSrR6bM9EZWJyrVyItwhciIY00EmIOmyZ5nU6HpUuXYsqUKVi/fr3JY1577TW8+uqrePnllzFp0iRoNBqUlpbaMiyX9PjC1D6TdvGfE6LEQgHumjkMj85P4X2d9qeHynsk+DA/CVLD/aAzGDEjOQRB3mJ8crAMc4aH4rapCQi3037tjuSStDCMivK32/XO1CkQIfNETbsaKWG+PQoxOYIjpS1Y8ckxJIX64Ks7J/dZdpkQ8he7dNdv2LABDz/8cK+WfFtbG6KiorB161bMmzdvUOem7vqBqXQGMGAgEjIO88G9/kAZihqUSA33xRUjIxDq535JvC9lzZ2oaVNjWlKQXb+M5dXIsbewCRUtnXjh6pEO2Vq+c2MWsqvasfORmbQdM3ELDt1dP5CdO3eCZVnU1NQgLS0NSqUSU6dOxauvvoqYmBiT79FqtdBqtd2PFQqFvcJ1WlKx482vvH16At8hOCSDkcWm41X4YG8JnrkyHSvtdJ+yq9qh1hlx/5wkk6/XydUoqFVgXlqYXeLpyzNXpuOlHWcpwRNiJl6/qpeWloJlWbzwwgt444038N1336G1tRXz58+HTqcz+Z5169ZBJpN1//T1ZYAQZ9PcocXM/+7GB3tLcOWoCHxro81stAYj7tyYhUMlzd3PHSxu7nPlRG61HPNe3YsdefU2icdcHMchzM8TD85L5jUOQpyJxUl+zZo1YBim35+srCyzzsWyLPR6Pd566y0sXLgQkydPxldffYWioiLs3r3b5HtWr14NuVze/VNVVWXp/wIhVtXaafoLqaVya+RoVemQEemHt5Zl4vPbJ1rlvBeTiIQYGxvQ/fjDfSXQ6o24YWLfX5iXT4nD38ZGW3SdipZOHCtrxaGSZnx3ohoGY9/LIwei0Rvx8q/nkPLUdjz41SmU22ApJyGuyOJ+3FWrVmHZsmX9HhMfH2/WuSIiIgAA6enp3c+FhIQgODgYlZWVJt8jkUggkdCEG+I4VDoDAr2H3n3s5ylC1lPz4SPp+rMMtlHRIQC4Z9aw7vH+u2Ym9nr9dFU7yls6MS8tDCOjZRgZLet1TH8UGj3e+aMY23Lr8M3dk6GWegxpjF+pMSDIR4JPbh2Pp7fko6KVv7oRhDgTi5N8cHAwgoODrXLxadOmAQDOnTuH6OiuVkJrayuam5sRFxdnlWsMxjfHq7DrbANaO3V48rLhGBfXe1kaIedFB/TeLXAwLP090+iNKG/pxPBwyyfjDDShT6M34qP9pdiRV4/3bx5n8fm1ehYTEgLhLRFBa+CGPJYf4ivpnscx9e/B6NQaul/TG1n8cLIGs1JDEEYTOAnpwaYzsiorK9Ha2orKykoYjUZkZ2cDAJKSkuDj44OUlBQsWbIEDz30ED788EP4+flh9erVGD58OObMmWPL0Pr13p5ilLeoMHlYIDIiLWvBEGIPHMfhXz/kwUcixHNLRlj9/JOGBWHDbRPR0jG4oYgQXwmuG2+b+TKeHsLu2gFagxGL3j4ABgxOVLThpWtH2eSahDgrmyb5Z555Bp999ln348zMrnKku3fvxuzZswEAGzduxCOPPIIrrrgCAoEAs2bNwo4dO+Dhwe8OZ6OiZfhoxfge+7s7I63BiGNlrWhT6TE1McimXcDEfs7WK/H9yWrMTu27XvxQBftIePt96dQaIBULB+xxkIiE+Oy2iYjw98KOvDo7RUeI86CytiYsX38Ub1w/xmYbsdiLUqPH3Z+fwKGSFgCASMBgRnIwVs1Nxri4gAHeTRzZf34uwM4zDRgd7Y+3buCnlj/HcdhwqBzLJ8dZdU19Tbsal7y6F1dlRuLBecn91up/f08Jsspbsf7WCVa7PiGOZKg5jpK8CU1KrUtU08qvleOxb3Nwpq5nLYGbJ8fiP1eN5Ckq0peLSw1rDUZIRP33JKl1RvxwqgY3Toq1dXgmFdQq8P3Jajx9ZbrJ1xuVGnx6sBx/n59i9heBez4/gR35Xcv1PD0EWDUnCavm9r1s7vxHGN9VHAmxhaHmOMcraeUATCV4Z/wulBEpwy8PTsfm+6biqjGREP1ZQ/1kRTu/gZFeSps68MBXp7CvsKn7ueNlbWhSatHSocUnB8pMvk/PsnhtZyGKG5Vo7dShpUOLjYfL8dKOs/1uafvJgTLUydVDjjs90q/PBA8AMi8P+EhEOFzaYtbf0N7Cpu4EDwCTEoJw+ciIft9zfukuIaQ3asmb4dODZcivVSA2UOpwhTgaFRqzS8JWtHTitZ2FmDs8FEvGRNk4MmKpOrkax8pae/3b7CxowEf7SvHNPVNMvq+yRYWYQC8seucA8mq6em0mxgfirRsy+6z5rzey+PxwRb8V9dpVOpyrV2LSsKBB/h9Zbn9RE3YWNCDUV4IImRf+NjaKEjhxa9Rdb+Mkz3Ec3v6jGIUNStw3Ownpkbatj6/U6LH1dB1CfCUwGFmEyzxR266BgAEWZoT32NFsZ0EDnv0xD1/eOZnWDPOsrLkTIb6S7jXu1tahNQx47jd/L8L05GAwDDAm2t/s3e/6ojOwyK1ppyWkhPCIkryNk3xrp84qhU7McbikBTd9fASsiX+RkVEy/LRqWo9Wze6zjVBo9NQq55GR5fDpwTK8uP0sogK88OrS0Rgfz09SNBjZQU+A0xtZtKv0LjEXhRBXQmPyNjbExpDZWJbD678XmkzwAPDQvORe3ZZzqNuddzVtavxn2xkYWA4VLSrctuE4GhWa7tfza+U4V6+02fV1Bhbsn7805iZ41sQvGctxuPvznvXszzte3oqs8tahBdoPpUZvs3MT4u4oyQ/AXrtd7SlsxLGyVghNfKlIDvXBvLTQXs83KjR4d3cxVm/OdZiJgZ1aA97aVeQw8djakdKWHo9DfCRo+bOWvcHI4pFN2bjt02NoG6C+fX6tHHduzLLovr24/Swe2ZQNQ1/fDE34OacWz/9c0Ot5iUiIzfdNw9TEntUstQYjlBo94oJsMxxU1tyJJ77Pscm5CSE8bzXr7HKq2zEq2t9K55LDy0MItd6IxBBvBHqLIWAYsByHdpUeD3x1CldnRnWXBz1Z2Ya/vXeo+/03Toy1uL54fwxGFgaWg1bPokGpgVgoMGvcP6uiDa/tLMTJyja8e+NYeNtojNpRnP2zlT4uLgB3zRyG+Wlh3WPhFa0qCBgGtXINfs6pxfIp8X2eJz3CD2/fkGnRJLMxMTLcODEWYpH539Vr2tTw8zT/30QiEmLucNttL+slFkChNqBerulzkiAhZPBc+xPYRvRGFnk1cqz75SyeWZSOEVGWJVcjy2FfURP2FTbB30uMO2cmoLZdDfWfS55KmjpR0tRzl63ipg5cM+6vXcASQ3wgEjDdrTi52rpdniq9ETP/uxvtqq7zCgUMXr52VL87kSk0ejz5Z6tsz7kmXPd/h/H57ZPsNqeBDxMTAnDFqAiTxYUSQ3zw8wPT0aDUInyAFRAMw1hcXfHSEf0vLTPl7lm9N6MZrI2HyjE1KRhJoT6DPkewtwS3TYvv8Vx2VTv2nGvEtKRgTOBpfgMhroK66wchr0aOV38rRGWrCj9m11j8fqGAgd7AIr9GgXf3FGPsv3diXFwAbp4ci2tMJFEBAzy2IBWzkv8qYSrz8sD4+K7EsnJaAqYlWXeZk5+nB355cAaWjotGoLcYyaE+uDqz//H/b45XoU5+4Xi0Ai//etZqMRXUKpBfK7fa+azh0hGmE/x5IqEAUf5eEA5xcseh4t5j5XxLDPVBVatqSOcQCQWYlxbW3YrnOA6PbsrGG78XYeWnx3HchnMBCHEH1JIfhMzYAHxxxyRwHIfixo5BnWNBRjgWZIRDpTPgZEU7BALg+gmx+O5ENc7WK7D26pE4VtaCucPDsHZbAfw8Rb2WRH1x+yQcKG7GrJQQm6wljvT3wstLR6NeroGBZQe8RkGtotdzTUrr7LVe1tyJOz47jgfnJbvkpkEqnQGbT9bg0hHhJuvFP7wpG88tzsBlAxSGudCL28+iuk2FV68bPWDlvMGYlmT+bpStnTpsPV2L2akh/Y7vsxxQ/+fExRFRMqSG+/Z5rFyth8yL3z0uCHF0lOSHgGEYJIf1/SFkDqlYhOnJf31YXjsuGldnRkEoYDAmxh8A8OltE02+VyQUYHZq7wl51mbuWGmEf+/jqtuG1tI7TywSoFauQWHD4L5UObrj5W3YllOHlDBfk0neRyLCT6drLUry981JhFo3cGnc8744UoGl46OH9IWgskWFf23JxcT4QDzwZ+GowyUteOjrU3jtujEDTuATChgsnxyHX/Lq8OltE/ocwthb2IRNxyvx3k2Wb4NLiDuhJO+Ahtq1y5drx8VgUkIQChuUOFbWit8KGrrH9IcqUuYJf6kHtIa+S7U6s1kpIZiZHNxnb0liqA/um51k0Tn9PD3g52l+S1ejN0I8hI1mWJbD2l8KsL+oGUdLW3H7jARIxSIMD/fFy0tH9/gy25/Vl6fh8UuH9/t3MCMpGNMt6EkgxF3RmDyxmoRgb8xMCcEdM4bh/ZvHIcrfC94S63QTMwyD68fHoFGptcr57CGnuh1fHKkwe1lcf8Mhby3LtOrqCVPumDHMrGGfY2W9x8l35NXj5vVH8Wt+AwAg0FsMjz+/MAR4izErxbItcQf6oisQME77ZZgQe6KWPLEJAQP4eop6zZweir8vSEVzh3MkeZblcLy8DScqWnGTFXaI8xJbf0x9sPy8en9sXDoiHEmhPli54TgMRha3zxjWneQJIfyhsrbEJpQaPd7fU4KHL0mxaB03cW4VLZ0I8/O0eDkgIcS0oeY4askTm/D19MDjlw7nOwxiZ7aqjEcIGRxqYhHi4FiWQ6NS0+M5aw5bKDR6GC0ojUsIcR6U5AlxcD+drsXW03Xdj3fk1WHj4QqrnFup0eOqdw/iie9zwHEcWJaDzsAO6ZwqnQGnKtusEh8hZGhoTJ4QM7y2sxD5NXJkxvpj+eR4yKT2K8KiN7JQ6YzdhV84jrNq8aP8WjkUagOmJAbhy6OV2Hi4HG/fkDmoGhBZ5a14cnMuSpo68Mb1Y2iXREKGiLaaJcQOLhsRjl1nG/HKb4V49Jtss5fF7TrTgO25dQMf2A8PoaBHZTdrVzfMiJRhSmJXWeT9RU04W6/EV8eqBnWutAg/hPpKEB3ghePlrSa3tSWE2A+15Akx0/NbC/DJwTIAwMaVEzHTwrXfljKyHFo7dQjx7V0Bz1y/5tfDz9OjO4kPpK1Th59z63D9+JgBV0WwLIdWlc5khT5CiHVQS544papWFX7OqcVLO87izo1Z6NQa+A5pQH8b+1fXc1SA14DH7y1sGtL15Go9vskaXIv6vOo2NfwtGFoI8BZj+eQ4s5Y9tqp0kDrQ+n1CSG+0hI7w4s1dRfjuRHX34+PlrXapwz8U0Rck9ialFokh/W+xWt2mQnOHdtAt3UBvMe6fY1kp24uNiZEheQhbwfaHWvCEOD5qyRO7U+uM+DmntsdzT36fi62na/t4h2Pwl4oRGygFAPxxtrHfY3cWNKC8uRMvbT8LuRn1+9/8vQinq9qtEWYP4+ICIRpi5bk6udpl9wwgxNVRS57w4pNbJ8DIcjCyHLbl1CHYV4LkMNu0OK1pVLQMte1qpEX0P/N8eLgvHv0mG0qNAQ/OSx5wNv789DA8tzUfG26b6DAlbAtqFdhwqAyFDR1YkBFm8QY5hBD+0cQ7QiywPbcOaRF+iA8euLLboZJmFNQqsHhMJEJ9B96uV67Wg2Fg0c5xfdHojVYpLas3slSDnhAeDTXHUZInxAkYjCx2nW1EapgvYgKl/e7A9tpv5/BLXj023TUZQf2Mmzd3aOEjEVGdeUIcGM2uJ8RJVbWq8G1WFc7VKwc8tqVTh//uOIvZr+zBy7+e6/fYW6bG4+0bMvtN8ADw0b5S1Mk1/R5DCHFulOQJ4Um4zBN7C5vMKgEb5ueJH+6fhtmpIfjyaAVOVPTe0/28IB8J0iIG/sb/0CXJSDBj2IEQ4ryou54QB3X+T/PCCnddm9VoES4beIyfEOL8qLueEBfDcRxWb87F3Ff3YkdefY/XBALGLgm+qEFpduleQojjoiRPnFZzh7ZHQR1b2HWmwawxc2tiGAbLJ8chMcTHrMp61rKzoAGlTR0AgOQwX6vXyCeE2B8leeK0PtpXise+PY0DRc02u8abu4rwyKZsm52/L+mRfnjvprFIDbd8J7hz9Ur85+cCZPdRXMdgZPHEdznYkVfXYwOZ2akhGDZAFT9CiHOhJE+c1j2zErHprsmYPCyw12tagxHbcupQ2aIa0jWiA7x4q88uFgkgEVl+bS8PISYmBGJMjL/J10VCAZaMicR7e0qQX6vofp7WwxPiemjiHXEJbZ06qPVGRMg8cby8Df/dcRYZkX54bsmIIZ1XqdGjslWFjEiZlSJ1PBUtnRAKGEQHSPkOhRBykaHmOCprS5wex3H4JqsKx8pasSAjDE98n4vMWH88MC95yOf29fRw6QQPAHFBtIyOEFdFSZ44vbd2FeNoWQvC/TzR2qnHJ7eOx+RhQZCKnffX+5fcOuw+24j75iTRWnZCyKA576cgIX96YG4SHhIMvdXuSEZEyvCfnwswOzW0zyT//Ylq5FS34+8LU61S754Q4npoTJ44lNp2NSL97bdszJG1q3TwkYj63Cq2qlWFmEDzxtGbO7QIkIr7rXlPCHE8VAyHuJTy5k6s++WMWXuwO5JtOXUob+606jl3FjRg9it78NpvpmvVm5vgP9xXghkv7UZLh9aa4RFCnAAleeJQpiYFI9TPE7vONvAditl2n23E/V+exJHSFquet7pNjdHR/sirVcBgZAd9nih/Kd5YNgahflQKlxB3Q2PyxC7aVTr4S8VmHXvLlDi0dupsHJF1nKtX4p4vTgCA2eVmWZbDoZIWhPpJkBTiA0EfXeiPzE+xSoxXjIqwynkIIc6HWvLEpowsh4/3l+Kmj49CqTGvC14kFDhNqzMxxBsvXTMKAPDVsUqz6r1XtamwI78Ov+TWwWiDKTEavXHAOPJr5Va/LiHE8VBLntiMwcjirs9P4HBJC2alhEBrYGF5kVbHJhIKcFVmFMQiAfy9zJvhHhfkjf9cNdKi63AcZ3Yt+W+zqvBbQQPun5OEycOCTB7j6mv/CSFdKMkTm9DojWhUaLFiShzevXEsvHgqDWsvl4+0TZc4x3H4+ngV8mrkWHu1eV8M1HojDpe0QKtn8c09U2wSFyHEOVCSJ1ZnZDnk1yowLi4AsUGuWSr104NlGB8XiLQI3z6XuFmDkeXwx9lGHCpuxt8XpCLQe+B5DXfNTES4zAuTE3rX9CeEuBcakydWJxQwGBcXwHcYNrX1dC0WvXMAp6ttO7YtEgrwwc3jcPuMYcipbjd7j/fFoyOdZl4DIcR2qCVPyCBMHhYEoYBBcpjtt2YVChg8aqWZ9oQQ90JJnpBBePzS4XyHQAghA6LuekIGUFCrwIGiZr7DIIQQi1GSJ2QAd3+Rhc+PlPMdBiGEWIySPCH9YFkOBiOH++ck8R1KL58fqcB9/zuB6jYV6uUafHWsEkbWqfebIoRYGSV5QvohEDA49ORcjIr27/F8g0KD/9tbgie+y+FtM50RkX7YnlePM3VKiEUCvPNHMWra1LzEQghxTDTxjpABmKo09/rOQnx9vAoAsGJqHGRS+1eQGx3tj1umxGN8XAACvMV496axkJlZdY8Q4h4oyRO3oTOw6NAacLZOAZnUA+kRftAZWUhEXdX42lU6ZFe1w0MoQIivBClhpovwNndo0dKpQ7CPBGNj/fs8ztYEAgZrFmd0Px4T489LHIQQx0VJnrgNA8tif1ETtufWQ2dkIWC61rvfMWMYAMBfKkaYnyf++UMuatvVOPzkPJM7xAX7SPDRivHIq5FjRBTVgCeEOC5K8sRtSMUiLBkThSVjovo8Ji3CD2Ni/FHVqsLeoibMSQ3t81hK8IQQR8dw5tbJdFAKhQIymQxyuRx+fn58h0NchCW7vhFCiK0MNcfR7HpCTBgowXMcZ3YdeUII4QsleUIsxHEcfjhVA1qSTghxdDZN8mvXrsXUqVMhlUrh7+9v8pjjx49j3rx58Pf3R0BAABYsWIDs7GxbhkXIkLSr9BgVLYPQxKQ8QghxJDZN8jqdDkuXLsW9995r8nWlUomFCxciNjYWR48exYEDB+Dn54eFCxdCr+enwAghAwnwFiMplJ9lc4QQYgm7TLzbsGEDHn74YbS3t/d4PisrCxMmTEBlZSViYmIAALm5uRg1ahSKi4uRmJg44Llp4h0hhBBX5dQT71JTUxEcHIz169dDp9NBrVZj/fr1yMjIQFxcnMn3aLVaKBSKHj+EEEII6Y3XJO/r64s9e/bgiy++gJeXF3x8fPDrr7/il19+gUhkegn/unXrIJPJun/O9wAQQgghpCeLk/yaNWvAMEy/P1lZWWadS61WY+XKlZg2bRqOHDmCgwcPIiMjA5dffjnUatMbbaxevRpyubz7p6qqytL/BUIIIcQtWFzxbtWqVVi2bFm/x8THx5t1ri+//BLl5eU4fPgwBAJB93MBAQH48ccfTV5HIpFAIpFYGjYhhBDidixO8sHBwQgODrbKxVUqFQQCQY/CI+cfsyxrlWsQQggh7sqmY/KVlZXIzs5GZWUljEYjsrOzkZ2djY6ODgDA/Pnz0dbWhvvvvx9nzpxBfn4+brvtNohEIsyZM8eWoRFCCCEuz6Yb1DzzzDP47LPPuh9nZmYCAHbv3o3Zs2dj+PDh2Lp1K5577jlMmTIFAoEAmZmZ2LFjByIiImwZGiGEEOLyaIMaQgghxEE59Tp5QgghhNgOJXlCCCHERVGSJ4QQQlwUJXlCCCHERVGSJ4QQQlyUTZfQ2cP5xQG0UQ0hhBBXcz63DXYhnNMneaVSCQC0UQ0hhBCXpVQqIZPJLH6f06+TZ1kWtbW18PX17VEed7AUCgViYmJQVVVF6+4vQPelN7onptF9MY3uS290T0y78L74+vpCqVQiMjKye48XSzh9S14gECA6Otrq5/Xz86NfOhPovvRG98Q0ui+m0X3pje6Jaefvy2Ba8OfRxDtCCCHERVGSJ4QQQlwUJfmLSCQSPPvss7Rn/UXovvRG98Q0ui+m0X3pje6Jada8L04/8Y4QQgghplFLnhBCCHFRlOQJIYQQF0VJnhBCCHFRlOQJIYQQF+WWSX7dunWYMGECfH19ERoaiquuugrnzp3rfl2v1+OJJ57AyJEj4e3tjcjISKxYsQK1tbU8Rm17A92Xi919991gGAZvvPGG/YLkgbn35cyZM1i8eDFkMhl8fX0xefJkVFZW8hCx7ZlzTzo6OrBq1SpER0fDy8sLaWlpeP/993mK2D7ef/99jBo1qruIyZQpU7B9+/bu1zmOw5o1axAZGQkvLy/Mnj0b+fn5PEZse/3dE3f9rAUG/l250FA+a90yye/duxf3338/jhw5gp07d8JgMGDBggXo7OwEAKhUKpw8eRJPP/00Tp48ic2bN6OwsBCLFy/mOXLbGui+XGjLli04evQoIiMjeYjUvsy5LyUlJZg+fTqGDx+OPXv24PTp03j66afh6enJY+S2Y849eeSRR7Bjxw588cUXOHPmDB555BE88MAD+PHHH3mM3Laio6Px4osvIisrC1lZWZg7dy6WLFnSncj/+9//4rXXXsM777yD48ePIzw8HPPnz+/eg8MV9XdP3PWzFhj4d+W8IX/WcoRrbGzkAHB79+7t85hjx45xALiKigo7Rsavvu5LdXU1FxUVxeXl5XFxcXHc66+/zk+APDF1X66//nru5ptv5jEqfpm6JxkZGdzzzz/f47ixY8dyTz31lL3D41VAQAD38ccfcyzLcuHh4dyLL77Y/ZpGo+FkMhn3wQcf8Bih/Z2/J6a442fteRffF2t81rplS/5icrkcABAYGNjvMQzDwN/f305R8c/UfWFZFsuXL8c//vEPZGRk8BUary6+LyzLYtu2bUhJScHChQsRGhqKSZMmYcuWLTxGaV+mflemT5+On376CTU1NeA4Drt370ZhYSEWLlzIV5h2ZTQa8fXXX6OzsxNTpkxBWVkZ6uvrsWDBgu5jJBIJZs2ahUOHDvEYqf1cfE9MccfPWlP3xWqftdb7DuKcWJblFi1axE2fPr3PY9RqNTdu3DjupptusmNk/Orrvrzwwgvc/PnzOZZlOY7j3K4lb+q+1NXVcQA4qVTKvfbaa9ypU6e4devWcQzDcHv27OExWvvo63dFq9VyK1as4ABwIpGIE4vF3MaNG3mK0n5ycnI4b29vTigUcjKZjNu2bRvHcRx38OBBDgBXU1PT4/g777yTW7BgAR+h2k1f9+Ri7vZZ2999sdZnrdPvQjdUq1atQk5ODg4cOGDydb1ej2XLloFlWbz33nt2jo4/pu7LiRMn8Oabb+LkyZNW2dbXGZm6LyzLAgCWLFmCRx55BAAwZswYHDp0CB988AFmzZrFS6z20tff0FtvvYUjR47gp59+QlxcHPbt24f77rsPERERuOSSS3iK1vZSU1ORnZ2N9vZ2fP/997jllluwd+/e7tcv/tvhOM7l/576uifp6endx7jjZ21f90WtVlvvs9ZKX0ic0qpVq7jo6GiutLTU5Os6nY676qqruFGjRnHNzc12jo4/fd2X119/nWMYhhMKhd0/ADiBQMDFxcXxE6wd9XVftFotJxKJuH//+989nn/88ce5qVOn2jNEu+vrnqhUKs7Dw4P7+eefezx/++23cwsXLrRniLybN28ed9ddd3ElJSUcAO7kyZM9Xl+8eDG3YsUKnqLjx/l7cp67ftZe7Px9seZnrVu25DmOwwMPPIAffvgBe/bsQUJCQq9j9Ho9rrvuOhQVFWH37t0ICgriIVL7Gui+LF++vFcLbOHChVi+fDluu+02e4ZqVwPdF7FYjAkTJvRaQlZYWIi4uDh7hmo3A90TvV4PvV4PgaDntB+hUNjd8+EuOI6DVqtFQkICwsPDsXPnTmRmZgIAdDod9u7di5deeonnKO3r/D0B3POzti/n74tVP2ut/EXEKdx7772cTCbj9uzZw9XV1XX/qFQqjuM4Tq/Xc4sXL+aio6O57OzsHsdotVqeo7edge6LKe4wJm/Ofdm8eTPn4eHBffjhh1xRURH39ttvc0KhkNu/fz+PkduOOfdk1qxZXEZGBrd7926utLSU+/TTTzlPT0/uvffe4zFy21q9ejW3b98+rqysjMvJyeH++c9/cgKBgPvtt984juO4F198kZPJZNzmzZu53Nxc7oYbbuAiIiI4hULBc+S20989cdfPWo4b+HflYoP9rHXLJA/A5M+nn37KcRzHlZWV9XnM7t27eY3dlga6L6a4Q5I3976sX7+eS0pK4jw9PbnRo0dzW7Zs4SdgOzDnntTV1XG33norFxkZyXl6enKpqancq6++2j2RyBWtXLmSi4uL48RiMRcSEsLNmzevx4c2y7Lcs88+y4WHh3MSiYSbOXMml5uby2PEttffPXHXz1qOG/h35WKD/aylrWYJIYQQF0Xr5AkhhBAXRUmeEEIIcVGU5AkhhBAXRUmeEEIIcVGU5AkhhBAXRUmeEEIIcVGU5AkhhBAXRUmeEEIIcVGU5AkhhBAXRUmeEEIIcVGU5AkhhBAXRUmeEEIIcVH/DwXRIqfsg5qKAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in the survey data\n",
    "country_sea = gpd.read_file('/capstone/mosaiks/repos/preprocessing/data/ground_data_spatial/updated_data.shp')\n",
    "# Filter country_sea for unique values of 'seq_unq' and 'geometry'\n",
    "sea_unq_join = country_sea[['sea_unq', 'geometry']].drop_duplicates()\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "sea_unq_join.plot(ax=ax)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf41a538-1070-4f5e-938a-33738b7a3aa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in the survey data\n",
    "sea = gpd.read_file('/capstone/mosaiks/repos/preprocessing/sitian/data/SEA_Shape_all.shp')\n",
    "boundaries = gpd.read_file('/capstone/mosaiks/box/Shapefiles/spatial/zam_districts/ZAM_Districts.shp')\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "boundaries.plot(ax=ax)\n",
    "sea.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8c1edf9-7ff3-42ed-b11d-06440ec3eeec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((28.71362 -14.50631, 28.71365 -14.506...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((28.66956 -14.63660, 28.66957 -14.636...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((28.51828 -14.57855, 28.51901 -14.579...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((28.67764 -14.88801, 28.68266 -14.887...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((28.34812 -14.82430, 28.34812 -14.824...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>644</td>\n",
       "      <td>POLYGON ((24.74318 -17.29921, 24.74343 -17.299...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>645</td>\n",
       "      <td>POLYGON ((24.46976 -17.42445, 24.47061 -17.425...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>646</td>\n",
       "      <td>POLYGON ((24.34614 -17.47451, 24.34577 -17.474...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>647</td>\n",
       "      <td>POLYGON ((24.36564 -16.62152, 24.35000 -16.617...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>648</td>\n",
       "      <td>POLYGON ((23.59670 -16.25869, 23.59183 -16.259...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FID                                           geometry\n",
       "0      0  POLYGON ((28.71362 -14.50631, 28.71365 -14.506...\n",
       "1      1  POLYGON ((28.66956 -14.63660, 28.66957 -14.636...\n",
       "2      2  POLYGON ((28.51828 -14.57855, 28.51901 -14.579...\n",
       "3      3  POLYGON ((28.67764 -14.88801, 28.68266 -14.887...\n",
       "4      4  POLYGON ((28.34812 -14.82430, 28.34812 -14.824...\n",
       "..   ...                                                ...\n",
       "644  644  POLYGON ((24.74318 -17.29921, 24.74343 -17.299...\n",
       "645  645  POLYGON ((24.46976 -17.42445, 24.47061 -17.425...\n",
       "646  646  POLYGON ((24.34614 -17.47451, 24.34577 -17.474...\n",
       "647  647  POLYGON ((24.36564 -16.62152, 24.35000 -16.617...\n",
       "648  648  POLYGON ((23.59670 -16.25869, 23.59183 -16.259...\n",
       "\n",
       "[649 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundaries\n",
    "sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbe3e8ca-f209-4c76-a209-1c49d83c81a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>0_4</th>\n",
       "      <th>0_5</th>\n",
       "      <th>0_6</th>\n",
       "      <th>0_7</th>\n",
       "      <th>0_8</th>\n",
       "      <th>0_9</th>\n",
       "      <th>0_10</th>\n",
       "      <th>...</th>\n",
       "      <th>999_3</th>\n",
       "      <th>999_4</th>\n",
       "      <th>999_5</th>\n",
       "      <th>999_6</th>\n",
       "      <th>999_7</th>\n",
       "      <th>999_8</th>\n",
       "      <th>999_9</th>\n",
       "      <th>999_10</th>\n",
       "      <th>999_11</th>\n",
       "      <th>999_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.157999e-06</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.115388</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.008277e-03</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006789</td>\n",
       "      <td>0.006789</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.004724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>2.590917e-05</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>0.005251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.113844e-07</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.007540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.700000e-06</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.018616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 12000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0_1       0_2       0_3       0_4       0_5      0_6       0_7  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "1  0.001141  0.000329  0.000329  0.000329  0.000000  0.00000  0.000000   \n",
       "2  0.000006  0.000006  0.000006  0.000006  0.000004  0.00001  0.000014   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "\n",
       "            0_8       0_9      0_10  ...     999_3     999_4     999_5  \\\n",
       "0  6.157999e-06  0.000207  0.000000  ...  1.000000  1.000000  0.274676   \n",
       "1  1.008277e-03  0.001360  0.002211  ...  0.006789  0.006789  1.000000   \n",
       "2  2.590917e-05  0.000110  0.000109  ...  0.005561  0.005561  0.006391   \n",
       "3  3.113844e-07  0.000012  0.000000  ...  0.005570  0.005570  0.006739   \n",
       "4  9.700000e-06  0.000186  0.000166  ...  1.000000  1.000000  1.000000   \n",
       "\n",
       "      999_6     999_7     999_8     999_9    999_10    999_11    999_12  \n",
       "0  1.000000  0.115388  0.002708  0.001319  1.000000  1.000000  1.000000  \n",
       "1  1.000000  1.000000  0.000517  0.000343  0.000396  0.000327  0.004724  \n",
       "2  0.004212  0.003235  0.001937  0.001683  0.001970  0.002340  0.005251  \n",
       "3  0.003991  0.002857  0.001979  0.001435  0.001284  0.001814  0.007540  \n",
       "4  1.000000  0.002690  0.001603  0.000820  0.001269  0.001692  0.018616  \n",
       "\n",
       "[5 rows x 12000 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = grouped_features.iloc[:,5:12005]\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0640f9c-6682-4d85-866c-f7d2be3135cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_area_harv_ha</th>\n",
       "      <th>total_area_lost_ha</th>\n",
       "      <th>total_harv_kg</th>\n",
       "      <th>yield_kgha</th>\n",
       "      <th>frac_area_harv</th>\n",
       "      <th>frac_area_loss</th>\n",
       "      <th>area_lost_fire</th>\n",
       "      <th>maize</th>\n",
       "      <th>groundnuts</th>\n",
       "      <th>mixed_beans</th>\n",
       "      <th>...</th>\n",
       "      <th>prop_mix</th>\n",
       "      <th>log_maize</th>\n",
       "      <th>log_sweetpotatoes</th>\n",
       "      <th>log_groundnuts</th>\n",
       "      <th>log_soybeans</th>\n",
       "      <th>loss_ind</th>\n",
       "      <th>drought_loss_ind</th>\n",
       "      <th>flood_loss_ind</th>\n",
       "      <th>animal_loss_ind</th>\n",
       "      <th>pest_loss_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>57.894737</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.894737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.058626</td>\n",
       "      <td>5.269229</td>\n",
       "      <td>7.640386</td>\n",
       "      <td>6.977090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>607.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>8730.0</td>\n",
       "      <td>8.592520</td>\n",
       "      <td>0.597441</td>\n",
       "      <td>0.402559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.583333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181102</td>\n",
       "      <td>3.387211</td>\n",
       "      <td>0.689155</td>\n",
       "      <td>7.707512</td>\n",
       "      <td>7.113191</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>462.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>7930.0</td>\n",
       "      <td>12.162577</td>\n",
       "      <td>0.708589</td>\n",
       "      <td>0.291411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.938398</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>5.366667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069018</td>\n",
       "      <td>2.703935</td>\n",
       "      <td>8.486127</td>\n",
       "      <td>-1.408767</td>\n",
       "      <td>7.141370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>410.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>19975.0</td>\n",
       "      <td>36.651376</td>\n",
       "      <td>0.752294</td>\n",
       "      <td>0.247706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.048593</td>\n",
       "      <td>28.629032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.714757</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>3.354421</td>\n",
       "      <td>6.929734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>252.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>5175.0</td>\n",
       "      <td>14.785714</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.230366</td>\n",
       "      <td>17.324561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.786884</td>\n",
       "      <td>8.509161</td>\n",
       "      <td>2.852125</td>\n",
       "      <td>0.798508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_area_harv_ha  total_area_lost_ha  total_harv_kg  yield_kgha  \\\n",
       "0                71.0                 5.0         4400.0   57.894737   \n",
       "1               607.0               409.0         8730.0    8.592520   \n",
       "2               462.0               190.0         7930.0   12.162577   \n",
       "3               410.0               135.0        19975.0   36.651376   \n",
       "4               252.0                98.0         5175.0   14.785714   \n",
       "\n",
       "   frac_area_harv  frac_area_loss  area_lost_fire      maize  groundnuts  \\\n",
       "0        0.934211        0.065789             0.0  57.894737    0.000000   \n",
       "1        0.597441        0.402559             0.0  29.583333    0.000000   \n",
       "2        0.708589        0.291411             0.0  14.938398    0.244444   \n",
       "3        0.752294        0.247706             0.0  41.048593   28.629032   \n",
       "4        0.720000        0.280000             0.0  16.230366   17.324561   \n",
       "\n",
       "   mixed_beans  ...  prop_mix  log_maize  log_sweetpotatoes  log_groundnuts  \\\n",
       "0     0.000000  ...  0.000000   4.058626           5.269229        7.640386   \n",
       "1     0.434783  ...  0.181102   3.387211           0.689155        7.707512   \n",
       "2     5.366667  ...  0.069018   2.703935           8.486127       -1.408767   \n",
       "3     0.000000  ...  0.000000   3.714757           2.525729        3.354421   \n",
       "4     0.000000  ...  0.000000   2.786884           8.509161        2.852125   \n",
       "\n",
       "   log_soybeans  loss_ind  drought_loss_ind  flood_loss_ind  animal_loss_ind  \\\n",
       "0      6.977090       0.0               0.0             0.0              0.0   \n",
       "1      7.113191       1.0               1.0             0.0              0.0   \n",
       "2      7.141370       1.0               0.0             0.0              0.0   \n",
       "3      6.929734       1.0               0.0             0.0              0.0   \n",
       "4      0.798508       1.0               0.0             0.0              0.0   \n",
       "\n",
       "   pest_loss_ind  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = grouped_features.iloc[:,12006:]\n",
    "\n",
    "outcomes[\"loss_ind\"].astype('category')\n",
    "outcomes[\"drought_loss_ind\"].astype('category')\n",
    "outcomes['pest_loss_ind'].astype('category')\n",
    "outcomes['animal_loss_ind'].astype('category')\n",
    "outcomes['flood_loss_ind'].astype('category')\n",
    "outcomes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e3288b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model\n",
    "\n",
    "We define a model to predict each of our outcome variables on our features for each SEA/year. The `train_and_evaluate_models` function trains and evaluates Ridge Linear Regression models for each target variable specified in the `target_columns` parameter. It handles both categorical and continuous target variables and provides the option to block sample on specific SEAs (Survey Enumeration Areas) by providing the SEA IDs to hold out for the validation set.\n",
    "\n",
    "The function works as follows:\n",
    "\n",
    "1. Read the grouped features and outcomes from a CSV file.\n",
    "2. Define a helper function `block_sampling` to perform block sampling based on the provided SEA IDs.\n",
    "3. For each target variable in `target_columns`, select the corresponding target variable data.\n",
    "4. If `block_sea_ids` is provided and not empty, perform block sampling using the `block_sampling` helper function. Otherwise, use `train_test_split` to split the data into training and testing sets.\n",
    "5. Train a Ridge Linear Regression model using RidgeCV with 5-fold cross-validation and a range of alpha values.\n",
    "6. If the target variable is categorical, calculate and print the false positive rate and AUC-ROC. If the target variable is continuous, calculate and print the estimated regularization parameter, training R2 performance, validation R2 performance, and Pearson's correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4870dc-25d2-4eab-8bae-f752633f0150",
   "metadata": {},
   "source": [
    "### Helper Function for Confusion Matrix for Categorical Variables\n",
    "`calculate_confusion_matrix`:\n",
    "This function calculates the confusion matrix for binary classification problems based on the given true labels (`y_true`), predicted values (`y_pred`), and a decision boundary (`decision_boundary`). The decision boundary is used to threshold the predicted values to obtain binary predictions.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "`y_true`: The true labels of the target variable (a pandas Series or numpy array).\n",
    "\n",
    "`y_pred`: The predicted values of the target variable (a numpy array).\n",
    "\n",
    "`decision_boundary`: A float value that serves as the threshold for classifying the predicted values into two classes (0 or 1).\n",
    "\n",
    "\n",
    "The function performs the following steps:\n",
    "1. It adjusts the predicted values by setting them to 1 if they are greater than or equal to the decision boundary, and 0 otherwise.\n",
    "2. It calculates the confusion matrix using the true labels and adjusted predicted values.\n",
    "3. Depending on the shape of the confusion matrix, it extracts the true negatives (tn), false positives (fp), false negatives (fn), and true positives (tp).\n",
    "4. If the shape of the confusion matrix is not (1, 1) or (2, 2), it raises an error.\n",
    "\n",
    "Output: The function returns the values of tn, fp, fn, and tp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5ac3bf3-e040-420d-8290-7c1aa96c7f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_confusion_matrix(y_true, y_pred, decision_boundary):\n",
    "    y_pred_adj = np.where(y_pred >= decision_boundary, 1, 0)\n",
    "    cm = confusion_matrix(y_true, y_pred_adj)\n",
    "    if cm.shape == (1, 1):\n",
    "        if y_true.iloc[0] == 0:\n",
    "            tn, fp, fn, tp = cm[0, 0], 0, 0, 0\n",
    "        else:\n",
    "            tn, fp, fn, tp = 0, 0, 0, cm[0, 0]\n",
    "    elif cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "    else:\n",
    "        print(\"Unexpected confusion matrix:\")\n",
    "        print(cm)\n",
    "        raise ValueError('Unexpected confusion matrix shape.')\n",
    "    return tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b404d188-5f43-4ebb-a248-23fb763ebe6a",
   "metadata": {},
   "source": [
    "### Helper Function for Block Sampling on SEAs\n",
    "\n",
    "This function randomly selects a specified number of unique SEA IDs from the `grouped_features` DataFrame.\n",
    "\n",
    "Inputs:\n",
    "\n",
    "1. n: The number of unique SEA IDs to select.\n",
    "\n",
    "2. `grouped_features`: A DataFrame containing the feature data with a column '`sea_unq`' that stores the unique SEA IDs.\n",
    "\n",
    "The function performs the following steps:\n",
    "\n",
    "1. It extracts the unique SEA IDs from the '`sea_unq`' column of the `grouped_features` DataFrame.\n",
    "\n",
    "2. It randomly selects n SEA IDs from the unique SEA IDs without replacement.\n",
    "\n",
    "Output: The function returns a numpy array of the randomly selected SEA IDs.\n",
    "\n",
    "These helper functions are used in the main model as follows:\n",
    "\n",
    "`calculate_confusion_matrix` is used to calculate the confusion matrix for the categorical target variables. It is called in the `train_and_evaluate_models` function to compute the false positive rate and AUC-ROC for different decision boundaries.\n",
    "\n",
    "`randomly_select_seas` is not used in the current implementation of the main model. However, it can be used to randomly select SEA IDs if you want to implement a custom sampling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f762185-2e35-48c4-b203-cd5b5c7cd7c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def randomly_select_seas(n, grouped_features):\n",
    "    unique_seas = grouped_features['sea_unq'].unique()\n",
    "    selected_seas = np.random.choice(unique_seas, n, replace=False)\n",
    "    return selected_seas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0f34a8-0a0a-471f-9aba-b44699b0cb4d",
   "metadata": {},
   "source": [
    "## Cross-Validator Custom Class\n",
    "\n",
    "This custom cross-validator class, BlockSamplingCV, inherits from the BaseCrossValidator class in scikit-learn. It is designed to perform block sampling for cross-validation, holding out specific groups of observations (in this case, SEA IDs) during each split. This ensures that all observations with the same SEA ID are either in the training set or the test set, but not both.\n",
    "\n",
    "Here's a detailed explanation of the class:\n",
    "\n",
    "__init__(self, n_splits=5, n_seas_to_hold_out=10, sea_ids=None, random_state=None):\n",
    "The constructor takes the following arguments:\n",
    "\n",
    "n_splits: The number of cross-validation splits (default is 5).\n",
    "n_seas_to_hold_out: The number of SEAs to hold out in each cross-validation split (default is 10).\n",
    "sea_ids: A list or array of SEA IDs corresponding to the rows of the dataset (default is None).\n",
    "random_state: An integer seed or a RandomState instance for reproducible results (default is None).\n",
    "The constructor initializes the class with these arguments.\n",
    "\n",
    "_iter_test_indices(self, X=None, y=None, groups=None):\n",
    "This method generates test indices for each cross-validation split. It takes the following optional arguments:\n",
    "\n",
    "X: Feature matrix (not used in this method but included for compatibility with scikit-learn).\n",
    "y: Target variable (not used in this method but included for compatibility with scikit-learn).\n",
    "groups: Group labels for the samples used to ensure that each group is either entirely in the training or test set (not used in this method but included for compatibility with scikit-learn).\n",
    "The method performs the following steps:\n",
    "\n",
    "a. It calculates the total number of samples and extracts the unique SEA IDs from the sea_ids attribute.\n",
    "b. It initializes a random number generator with the specified random_state.\n",
    "c. For each split, it randomly selects a set of n_seas_to_hold_out SEA IDs without replacement.\n",
    "d. It finds the indices of the observations with the selected SEA IDs and yields them as test indices for the current split.\n",
    "\n",
    "The BlockSamplingCV class is designed to perform cross-validation with block sampling, where groups of observations (in this case, SEA IDs) are held out together during each split. This is useful because it ensures that all observations with the same SEA ID are either in the training set or the test set, but not both. This can help prevent leakage of information between the training and test sets when observations with the same SEA ID are strongly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ae68cdc-b4f5-4ba6-88bb-fe34d73965e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_val_test_indices(sea_ids, n_seas_to_hold_out_for_val, n_seas_to_hold_out_for_test, random_state):\n",
    "    unique_seas = np.unique(sea_ids)\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(unique_seas)\n",
    "\n",
    "    # Hold out some SEAs for testing\n",
    "    test_seas = unique_seas[:n_seas_to_hold_out_for_test]\n",
    "    remaining_seas = unique_seas[n_seas_to_hold_out_for_test:]\n",
    "\n",
    "    # Hold out some SEAs for validation\n",
    "    val_seas = remaining_seas[:n_seas_to_hold_out_for_val]\n",
    "    train_seas = remaining_seas[n_seas_to_hold_out_for_val:]\n",
    "\n",
    "    # Convert boolean indices to integer indices\n",
    "    train_indices = np.where(sea_ids.isin(train_seas))[0]\n",
    "    val_indices = np.where(sea_ids.isin(val_seas))[0]\n",
    "    test_indices = np.where(sea_ids.isin(test_seas))[0]\n",
    "\n",
    "    return train_indices, val_indices, test_indices, train_seas, val_seas, test_seas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "103c6d0b-6ef4-45cf-a477-748618b6d4d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare the arguments as a dictionary\n",
    "args = {\n",
    "    'target_columns': ['frac_area_harv', 'log_maize'],\n",
    "    'test_size': 0.1,\n",
    "    'categorical_columns':[],\n",
    "    'decision_boundaries': [0.5],\n",
    "    'sea_ids': grouped_features['sea_unq'],\n",
    "    'validation_size' : 0.1,\n",
    "    'bootstrap' : True,\n",
    "    'n_bootstraps': 10,\n",
    "    'block_sample': False,\n",
    "    'n_seas_held_out_val': None,\n",
    "    'n_seas_held_out_test': None,\n",
    "    'random_state': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a5cab05-0deb-48b4-be47-b12c73bbca52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(args):\n",
    "    target_columns = args['target_columns']\n",
    "    test_size = args.get('test_size', 0.1)\n",
    "    categorical_columns = args['categorical_columns']\n",
    "    decision_boundaries = args['decision_boundaries']\n",
    "    sea_ids = args['sea_ids']\n",
    "    validation_size = args.get('validation_size', 0.1)\n",
    "    bootstrap = args.get('bootstrap', False)\n",
    "    n_bootstraps = args.get('n_bootstraps', 0)\n",
    "    block_sample = args.get('block_sample', False)\n",
    "    random_state = args.get('random_state', False)\n",
    "    n_seas_held_out_val = args.get('n_seas_held_out_val', 30)\n",
    "    n_seas_held_out_test = args.get('n_seas_held_out_test', 10)\n",
    "    \n",
    "    \n",
    "    grouped_features = pd.read_csv(\"/capstone/mosaiks/repos/modeling/data/model_directory/SEA_averaged_features_simple_impute_modeltrain.csv\")\n",
    "\n",
    "    features = grouped_features.iloc[:, 5:12005]\n",
    "    outcomes = grouped_features.iloc[:, 12006:]\n",
    "\n",
    "    # Initialize an empty DataFrame to store the predictions\n",
    "    predictions_df = pd.DataFrame()\n",
    "    \n",
    "    # Initialize an empty DataFrame to store groundtruth\n",
    "    groundtruth_df = pd.DataFrame()\n",
    "    all_ridge_models=dict()\n",
    "    # Initialize an empty DataFrame to store the train data\n",
    "    train_df = pd.DataFrame()\n",
    "\n",
    "    # Initialize an empty DataFrame to store the validation data\n",
    "    val_df = pd.DataFrame()\n",
    "\n",
    "    \n",
    "    \n",
    "    print(f\"\\nRunning model with the following parameters:\")\n",
    "    print(f\"Target columns: {target_columns}\")\n",
    "    print(f\"Test size: {test_size}\", f\"Validation size: {validation_size}\")\n",
    "    print(f\"Bootstrap: {bootstrap}\")\n",
    "    print(f\"Random State: {random_state}\")\n",
    "    if bootstrap:\n",
    "        print(f\"Number of bootstrapped samples: {n_bootstraps}\")\n",
    "    print(f\"Block sample: {block_sample}\\n\")\n",
    "    # If block_sample is True, then use block sampling\n",
    "    if block_sample:\n",
    "        # Get train, validation and test indices\n",
    "        train_indices, val_indices, test_indices, train_seas, val_seas, test_seas = get_train_val_test_indices(sea_ids, n_seas_to_hold_out_for_val=n_seas_held_out_val, n_seas_to_hold_out_for_test=n_seas_held_out_test, random_state=random_state)\n",
    "        print(f\"Number of seas held out for validation: {n_seas_held_out_val}\\n\")\n",
    "        print(f\"Training SEAs: {train_seas}\")\n",
    "        print(f\"Validation SEAs: {val_seas}\")\n",
    "        print(f\"Testing SEAs: {test_seas}\")\n",
    "        \n",
    "\n",
    "    for target_column in target_columns:\n",
    "\n",
    "        # If block_sample is True, then use block sampling\n",
    "        if bootstrap and block_sample:\n",
    "            X_train, X_test = features.iloc[train_indices], features.iloc[test_indices]\n",
    "            y_train, y_test = outcomes[target_column].iloc[train_indices], outcomes[target_column].iloc[test_indices]\n",
    "            \n",
    "        elif bootstrap:\n",
    "            # Split the data into training and test sets\n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, outcomes[target_column], test_size=test_size, random_state=random_state)\n",
    "            \n",
    "        elif block_sample:\n",
    "            # Use the already obtained train_indices, val_indices, and test_indices\n",
    "            # Create train, validation and test sets using the indices\n",
    "            X_train, X_val, X_test = features.iloc[train_indices], features.iloc[val_indices], features.iloc[test_indices]\n",
    "            y_train, y_val, y_test = outcomes[target_column].iloc[train_indices], outcomes[target_column].iloc[val_indices], outcomes[target_column].iloc[test_indices]\n",
    "            \n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, outcomes[target_column], test_size=test_size, random_state = random_state)\n",
    "            # Split the training data again to create a validation set\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_size, random_state = random_state)\n",
    "\n",
    "        sea_ids_train = sea_ids[X_train.index]  # Update the sea_ids for the training set\n",
    "        sea_ids_test = sea_ids[X_test.index]  \n",
    "        \n",
    "        if bootstrap:\n",
    "            \n",
    "            ridge_models_scores = []  # Initialize an empty list to store the ridge models for this target column\n",
    "            val_scores =[]\n",
    "    \n",
    "            # Set the random seed for reproducibility\n",
    "            rng = np.random.default_rng(random_state)\n",
    "            # Define function for each bootstrap iteration\n",
    "            def bootstrap_iteration(i):\n",
    "                # Create a unique seed for this bootstrap iteration\n",
    "                seed = random_state + i\n",
    "                # Initialize the random number generator with the unique seed\n",
    "                rng = np.random.default_rng(seed)\n",
    "                # Create a bootstrapped training dataset\n",
    "                indices = rng.choice(len(X_train), size=len(X_train), replace=True)\n",
    "                X_train_bootstrap = X_train.iloc[indices]\n",
    "                y_train_bootstrap = y_train.iloc[indices]\n",
    "                X_train_bootstrap, X_val_bootstrap, y_train_bootstrap, y_val_bootstrap = train_test_split(X_train_bootstrap, y_train_bootstrap, test_size=validation_size, random_state=random_state)\n",
    "\n",
    "                # Print the first few rows of the bootstrap sample\n",
    "               # print(f\"Bootstrap sample {i}:\")\n",
    "               # print(pd.concat([X_train_bootstrap, y_train_bootstrap], axis=1).head())\n",
    "\n",
    "                # Fit the model to the bootstrapped data\n",
    "                cv = 5\n",
    "                ridge_cv = RidgeCV(cv=cv, alphas=np.logspace(-8, 8, base=10, num=75))\n",
    "                ridge_cv.fit(X_train_bootstrap, y_train_bootstrap)\n",
    "\n",
    "                # Make predictions\n",
    "                train_pred = ridge_cv.predict(X_train_bootstrap)\n",
    "                val_pred = ridge_cv.predict(X_val_bootstrap)\n",
    "\n",
    "                # Calculate scores\n",
    "                train_score = ridge_cv.score(X_train_bootstrap, y_train_bootstrap)\n",
    "                val_score = r2_score(y_val_bootstrap, ridge_cv.predict(X_val_bootstrap))  # Compute val_score here\n",
    "                \n",
    "                \n",
    "                # Calculate Pearson's correlation coefficient\n",
    "                pearson_coeff, _ = pearsonr(y_val_bootstrap, val_pred)\n",
    "\n",
    "                # Append model and score to lists\n",
    "                ridge_models_scores.append((ridge_cv, val_score))\n",
    "                val_scores.append(val_score)  # Append val_score after it's computed\n",
    "\n",
    "                all_ridge_models[target_column] = ridge_models_scores\n",
    "                \n",
    "                                # Calculate false positive rate and AUC-ROC if the target variable is categorical\n",
    "                if target_column in categorical_columns:\n",
    "                    y_val_pred = ridge_cv.predict(X_val_bootstrap)\n",
    "                    fpr = 0\n",
    "                    auc_roc = 0\n",
    "                    for decision_boundary in decision_boundaries:\n",
    "                        # Calculate confusion matrix\n",
    "                        tn, fp, fn, tp = calculate_confusion_matrix(y_val_bootstrap, y_val_pred, decision_boundary)\n",
    "                        # Calculate the false positive rate\n",
    "                        fpr += fp / (fp + tn)\n",
    "                        # Calculate AUC-ROC\n",
    "                        auc_roc += roc_auc_score(y_val_bootstrap, y_val_pred)\n",
    "                    fpr /= len(decision_boundaries)  # Get average false positive rate\n",
    "                    auc_roc /= len(decision_boundaries)  # Get average AUC-ROC\n",
    "                    return ridge_cv.coef_, train_score, val_score, pearson_coeff, fpr, auc_roc, (y_train_bootstrap, train_pred), (y_val_bootstrap, val_pred),ridge_models_scores\n",
    "                else:\n",
    "                    return ridge_cv.coef_, train_score, val_score, pearson_coeff, None, None, (y_train_bootstrap, train_pred), (y_val_bootstrap, val_pred),ridge_models_scores\n",
    "\n",
    "            # Run bootstrap iterations in parallel\n",
    "            results = Parallel(n_jobs=-1)(delayed(bootstrap_iteration)(i) for i in range(n_bootstraps))\n",
    "\n",
    "            # Unpack results\n",
    "            coefs, train_scores, val_scores, pearson_coeffs, false_positive_rates, auc_rocs, train_data, val_data,ridge_models_list = zip(*results)\n",
    "\n",
    "            all_ridge_models[target_column] = ridge_models_list\n",
    "\n",
    "            # Calculate the average coefficients and validation scores\n",
    "            avg_coefs = np.mean(coefs, axis=0)\n",
    "            avg_train_score = np.mean(train_scores)\n",
    "            avg_val_score = np.mean(val_scores)\n",
    "            avg_pearson_coeff = np.mean(pearson_coeffs)\n",
    "            \n",
    "                # Convert training and validation data to DataFrames\n",
    "            train_df_temp = pd.DataFrame([(y_train, pred) for y_train, pred in train_data], columns=[f'{target_column}_y_train', f'{target_column}_train_pred'])\n",
    "            val_df_temp = pd.DataFrame([(y_val, pred) for y_val, pred in val_data], columns=[f'{target_column}_y_val', f'{target_column}_val_pred'])\n",
    "\n",
    "            # Calculate the average prediction and value across each bootstrap sample for each target variable\n",
    "            train_df[f'{target_column}_y_train'] = train_df_temp[f'{target_column}_y_train'].apply(np.mean)\n",
    "            train_df[f'{target_column}_train_pred'] = train_df_temp[f'{target_column}_train_pred'].apply(np.mean)\n",
    "            val_df[f'{target_column}_y_val'] = val_df_temp[f'{target_column}_y_val'].apply(np.mean)\n",
    "            val_df[f'{target_column}_val_pred'] = val_df_temp[f'{target_column}_val_pred'].apply(np.mean)\n",
    "            \n",
    "                    # Concatenate the results to the existing dataframes\n",
    "            train_df = pd.concat([train_df, train_df_temp], axis=1)\n",
    "            val_df = pd.concat([val_df, val_df_temp], axis=1)\n",
    "\n",
    "\n",
    "            return None, None, None, train_df, val_df, all_ridge_models\n",
    "            \n",
    "            \n",
    "                        # Calculate the average false positive rate and AUC-ROC for categorical variables\n",
    "            if target_column in categorical_columns:\n",
    "                avg_false_positive_rate = np.nanmean(false_positive_rates)\n",
    "                avg_auc_roc = np.nanmean(auc_rocs)\n",
    "                print(f\"Average false positive rate: {avg_false_positive_rate:0.2f}\")\n",
    "                print(f\"Average AUC-ROC: {avg_auc_roc:0.2f}\")\n",
    "\n",
    "            print(f\"Target variable: {target_column}\")\n",
    "            print(f\"Average training R2 score: {avg_train_score:0.2f}\")\n",
    "            print(f\"Average validation R2 score: {avg_val_score:0.2f}\")\n",
    "            print(f\"Average Pearson's correlation coefficient: {avg_pearson_coeff:0.2f}\")\n",
    "            print()\n",
    "            \n",
    "\n",
    "        else:\n",
    "            cv = 5\n",
    "            ridge_cv = RidgeCV(cv=cv, alphas=np.logspace(-8, 8, base=10, num=75))\n",
    "            ridge_cv.fit(X_train, y_train)\n",
    "            \n",
    "\n",
    "            # Make predictions on the test data\n",
    "            y_val_pred = ridge_cv.predict(X_val)\n",
    "    \n",
    "            # Update the predictions DataFrame with the new predictions\n",
    "            predictions_df[target_column] = y_val_pred\n",
    "    \n",
    "            if target_column in categorical_columns:\n",
    "                for decision_boundary in decision_boundaries:\n",
    "                    # Calculate confusion matrix\n",
    "                    tn, fp, fn, tp = calculate_confusion_matrix(y_val, y_val_pred, decision_boundary)\n",
    "\n",
    "                # Calculate the false positive rate\n",
    "                    false_positive_rate = fp / (fp + tn)\n",
    "\n",
    "                # Calculate AUC-ROC\n",
    "                    auc_roc = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "                    print(f\"Target variable: {target_column} (Categorical)\")\n",
    "                    print(f\"Decision boundary: {decision_boundary}\")\n",
    "                    print(f\"False positive rate: {false_positive_rate:0.2f}\")\n",
    "                    print(f\"AUC-ROC: {auc_roc:0.2f}\")\n",
    "                    print()\n",
    "                    \n",
    "            else:\n",
    "                # Calculate Pearson's correlation coefficient\n",
    "                pearson_coeff, _ = pearsonr(y_val, y_val_pred)\n",
    "\n",
    "                # Calculate training R squared\n",
    "                train_r_squared = ridge_cv.score(X_train, y_train)\n",
    "\n",
    "                # Calculate validation R squared\n",
    "                val_r_squared = ridge_cv.score(X_val, y_val)\n",
    "                \n",
    "                metrics_df = metrics_df.append({\n",
    "                'target_column': target_column,\n",
    "                'train_score': train_r_squared,\n",
    "                'val_score': val_r_squared,\n",
    "                'pearson_coeff': pearson_coeff}, ignore_index=True)\n",
    "                    \n",
    "                print()\n",
    "                print(f\"Target variable: {target_column}\")\n",
    "                print(f\"Estimated regularization parameter: {ridge_cv.alpha_}\")\n",
    "                print(f\"Training R2 performance: {train_r_squared:0.2f}\")\n",
    "                print(f\"Validation R2 performance: {val_r_squared:0.2f}\")\n",
    "                print(f\"Pearson's correlation coefficient: {pearson_coeff:0.2f}\")\n",
    "                print()\n",
    "\n",
    "    return predictions_df, metrics_df, results_df, train_df, val_df, all_ridge_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09888b96-77c7-4611-8f2b-baba21ace8ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running model with the following parameters:\n",
      "Target columns: ['frac_area_harv', 'log_maize']\n",
      "Test size: 0.1 Validation size: 0.1\n",
      "Bootstrap: True\n",
      "Random State: 50\n",
      "Number of bootstrapped samples: 10\n",
      "Block sample: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_df, metrics_df, results_df, train_df, val_df, all_ridge_models = train_and_evaluate_models(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8766e12-8231-4b6b-a094-bd8c4c2ad71a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frac_area_harv': ([(RidgeCV(alphas=array([1.00000000e-08, 1.64519059e-08, 2.70665207e-08, 4.45295851e-08,\n",
       "           7.32596543e-08, 1.20526094e-07, 1.98288395e-07, 3.26222201e-07,\n",
       "           5.36697695e-07, 8.82969996e-07, 1.45265393e-06, 2.38989257e-06,\n",
       "           3.93182876e-06, 6.46860766e-06, 1.06420924e-05, 1.75082703e-05,\n",
       "           2.88044415e-05, 4.73887961e-05, 7.79636013e-05, 1.28264983e-04,\n",
       "           2.11020343e-04, 3.47168682e-0...\n",
       "           1.75082703e+03, 2.88044415e+03, 4.73887961e+03, 7.79636013e+03,\n",
       "           1.28264983e+04, 2.11020343e+04, 3.47168682e+04, 5.71158648e+04,\n",
       "           9.39664831e+04, 1.54592774e+05, 2.54334576e+05, 4.18428851e+05,\n",
       "           6.88395207e+05, 1.13254132e+06, 1.86324631e+06, 3.06539530e+06,\n",
       "           5.04315949e+06, 8.29695852e+06, 1.36500781e+07, 2.24569800e+07,\n",
       "           3.69460121e+07, 6.07832313e+07, 1.00000000e+08]),\n",
       "            cv=5),\n",
       "    0.635437085494561)],\n",
       "  [(RidgeCV(alphas=array([1.00000000e-08, 1.64519059e-08, 2.70665207e-08, 4.45295851e-08,\n",
       "           7.32596543e-08, 1.20526094e-07, 1.98288395e-07, 3.26222201e-07,\n",
       "           5.36697695e-07, 8.82969996e-07, 1.45265393e-06, 2.38989257e-06,\n",
       "           3.93182876e-06, 6.46860766e-06, 1.06420924e-05, 1.75082703e-05,\n",
       "           2.88044415e-05, 4.73887961e-05, 7.79636013e-05, 1.28264983e-04,\n",
       "           2.11020343e-04, 3.47168682e-0...\n",
       "           1.75082703e+03, 2.88044415e+03, 4.73887961e+03, 7.79636013e+03,\n",
       "           1.28264983e+04, 2.11020343e+04, 3.47168682e+04, 5.71158648e+04,\n",
       "           9.39664831e+04, 1.54592774e+05, 2.54334576e+05, 4.18428851e+05,\n",
       "           6.88395207e+05, 1.13254132e+06, 1.86324631e+06, 3.06539530e+06,\n",
       "           5.04315949e+06, 8.29695852e+06, 1.36500781e+07, 2.24569800e+07,\n",
       "           3.69460121e+07, 6.07832313e+07, 1.00000000e+08]),\n",
       "            cv=5),\n",
       "    0.28546958422877167)],\n",
       "  [(RidgeCV(alphas=array([1.00000000e-08, 1.64519059e-08, 2.70665207e-08, 4.45295851e-08,\n",
       "           7.32596543e-08, 1.20526094e-07, 1.98288395e-07, 3.26222201e-07,\n",
       "           5.36697695e-07, 8.82969996e-07, 1.45265393e-06, 2.38989257e-06,\n",
       "           3.93182876e-06, 6.46860766e-06, 1.06420924e-05, 1.75082703e-05,\n",
       "           2.88044415e-05, 4.73887961e-05, 7.79636013e-05, 1.28264983e-04,\n",
       "           2.11020343e-04, 3.47168682e-0...\n",
       "           1.75082703e+03, 2.88044415e+03, 4.73887961e+03, 7.79636013e+03,\n",
       "           1.28264983e+04, 2.11020343e+04, 3.47168682e+04, 5.71158648e+04,\n",
       "           9.39664831e+04, 1.54592774e+05, 2.54334576e+05, 4.18428851e+05,\n",
       "           6.88395207e+05, 1.13254132e+06, 1.86324631e+06, 3.06539530e+06,\n",
       "           5.04315949e+06, 8.29695852e+06, 1.36500781e+07, 2.24569800e+07,\n",
       "           3.69460121e+07, 6.07832313e+07, 1.00000000e+08]),\n",
       "            cv=5),\n",
       "    0.5656179111731081)],\n",
       "  [(RidgeCV(alphas=array([1.00000000e-08, 1.64519059e-08, 2.70665207e-08, 4.45295851e-08,\n",
       "           7.32596543e-08, 1.20526094e-07, 1.98288395e-07, 3.26222201e-07,\n",
       "           5.36697695e-07, 8.82969996e-07, 1.45265393e-06, 2.38989257e-06,\n",
       "           3.93182876e-06, 6.46860766e-06, 1.06420924e-05, 1.75082703e-05,\n",
       "           2.88044415e-05, 4.73887961e-05, 7.79636013e-05, 1.28264983e-04,\n",
       "           2.11020343e-04, 3.47168682e-0...\n",
       "           1.75082703e+03, 2.88044415e+03, 4.73887961e+03, 7.79636013e+03,\n",
       "           1.28264983e+04, 2.11020343e+04, 3.47168682e+04, 5.71158648e+04,\n",
       "           9.39664831e+04, 1.54592774e+05, 2.54334576e+05, 4.18428851e+05,\n",
       "           6.88395207e+05, 1.13254132e+06, 1.86324631e+06, 3.06539530e+06,\n",
       "           5.04315949e+06, 8.29695852e+06, 1.36500781e+07, 2.24569800e+07,\n",
       "           3.69460121e+07, 6.07832313e+07, 1.00000000e+08]),\n",
       "            cv=5),\n",
       "    0.7503280319393938)],\n",
       "  [(RidgeCV(alphas=array([1.00000000e-08, 1.64519059e-08, 2.70665207e-08, 4.45295851e-08,\n",
       "           7.32596543e-08, 1.20526094e-07, 1.98288395e-07, 3.26222201e-07,\n",
       "           5.36697695e-07, 8.82969996e-07, 1.45265393e-06, 2.38989257e-06,\n",
       "           3.93182876e-06, 6.46860766e-06, 1.06420924e-05, 1.75082703e-05,\n",
       "           2.88044415e-05, 4.73887961e-05, 7.79636013e-05, 1.28264983e-04,\n",
       "           2.11020343e-04, 3.47168682e-0...\n",
       "           1.75082703e+03, 2.88044415e+03, 4.73887961e+03, 7.79636013e+03,\n",
       "           1.28264983e+04, 2.11020343e+04, 3.47168682e+04, 5.71158648e+04,\n",
       "           9.39664831e+04, 1.54592774e+05, 2.54334576e+05, 4.18428851e+05,\n",
       "           6.88395207e+05, 1.13254132e+06, 1.86324631e+06, 3.06539530e+06,\n",
       "           5.04315949e+06, 8.29695852e+06, 1.36500781e+07, 2.24569800e+07,\n",
       "           3.69460121e+07, 6.07832313e+07, 1.00000000e+08]),\n",
       "            cv=5),\n",
       "    0.4881507129507521)],\n",
       "  [(RidgeCV(alphas=array([1.00000000e-08, 1.64519059e-08, 2.70665207e-08, 4.45295851e-08,\n",
       "           7.32596543e-08, 1.20526094e-07, 1.98288395e-07, 3.26222201e-07,\n",
       "           5.36697695e-07, 8.82969996e-07, 1.45265393e-06, 2.38989257e-06,\n",
       "           3.93182876e-06, 6.46860766e-06, 1.06420924e-05, 1.75082703e-05,\n",
       "           2.88044415e-05, 4.73887961e-05, 7.79636013e-05, 1.28264983e-04,\n",
       "           2.11020343e-04, 3.47168682e-0...\n",
       "           1.75082703e+03, 2.88044415e+03, 4.73887961e+03, 7.79636013e+03,\n",
       "           1.28264983e+04, 2.11020343e+04, 3.47168682e+04, 5.71158648e+04,\n",
       "           9.39664831e+04, 1.54592774e+05, 2.54334576e+05, 4.18428851e+05,\n",
       "           6.88395207e+05, 1.13254132e+06, 1.86324631e+06, 3.06539530e+06,\n",
       "           5.04315949e+06, 8.29695852e+06, 1.36500781e+07, 2.24569800e+07,\n",
       "           3.69460121e+07, 6.07832313e+07, 1.00000000e+08]),\n",
       "            cv=5),\n",
       "    0.6669083802982554)],\n",
       "  [(RidgeCV(alphas=array([1.00000000e-08, 1.64519059e-08, 2.70665207e-08, 4.45295851e-08,\n",
       "           7.32596543e-08, 1.20526094e-07, 1.98288395e-07, 3.26222201e-07,\n",
       "           5.36697695e-07, 8.82969996e-07, 1.45265393e-06, 2.38989257e-06,\n",
       "           3.93182876e-06, 6.46860766e-06, 1.06420924e-05, 1.75082703e-05,\n",
       "           2.88044415e-05, 4.73887961e-05, 7.79636013e-05, 1.28264983e-04,\n",
       "           2.11020343e-04, 3.47168682e-0...\n",
       "           1.75082703e+03, 2.88044415e+03, 4.73887961e+03, 7.79636013e+03,\n",
       "           1.28264983e+04, 2.11020343e+04, 3.47168682e+04, 5.71158648e+04,\n",
       "           9.39664831e+04, 1.54592774e+05, 2.54334576e+05, 4.18428851e+05,\n",
       "           6.88395207e+05, 1.13254132e+06, 1.86324631e+06, 3.06539530e+06,\n",
       "           5.04315949e+06, 8.29695852e+06, 1.36500781e+07, 2.24569800e+07,\n",
       "           3.69460121e+07, 6.07832313e+07, 1.00000000e+08]),\n",
       "            cv=5),\n",
       "    0.6134860049824769)],\n",
       "  [(RidgeCV(alphas=array([1.00000000e-08, 1.64519059e-08, 2.70665207e-08, 4.45295851e-08,\n",
       "           7.32596543e-08, 1.20526094e-07, 1.98288395e-07, 3.26222201e-07,\n",
       "           5.36697695e-07, 8.82969996e-07, 1.45265393e-06, 2.38989257e-06,\n",
       "           3.93182876e-06, 6.46860766e-06, 1.06420924e-05, 1.75082703e-05,\n",
       "           2.88044415e-05, 4.73887961e-05, 7.79636013e-05, 1.28264983e-04,\n",
       "           2.11020343e-04, 3.47168682e-0...\n",
       "           1.75082703e+03, 2.88044415e+03, 4.73887961e+03, 7.79636013e+03,\n",
       "           1.28264983e+04, 2.11020343e+04, 3.47168682e+04, 5.71158648e+04,\n",
       "           9.39664831e+04, 1.54592774e+05, 2.54334576e+05, 4.18428851e+05,\n",
       "           6.88395207e+05, 1.13254132e+06, 1.86324631e+06, 3.06539530e+06,\n",
       "           5.04315949e+06, 8.29695852e+06, 1.36500781e+07, 2.24569800e+07,\n",
       "           3.69460121e+07, 6.07832313e+07, 1.00000000e+08]),\n",
       "            cv=5),\n",
       "    0.8033572904474799)],\n",
       "  [(RidgeCV(alphas=array([1.00000000e-08, 1.64519059e-08, 2.70665207e-08, 4.45295851e-08,\n",
       "           7.32596543e-08, 1.20526094e-07, 1.98288395e-07, 3.26222201e-07,\n",
       "           5.36697695e-07, 8.82969996e-07, 1.45265393e-06, 2.38989257e-06,\n",
       "           3.93182876e-06, 6.46860766e-06, 1.06420924e-05, 1.75082703e-05,\n",
       "           2.88044415e-05, 4.73887961e-05, 7.79636013e-05, 1.28264983e-04,\n",
       "           2.11020343e-04, 3.47168682e-0...\n",
       "           1.75082703e+03, 2.88044415e+03, 4.73887961e+03, 7.79636013e+03,\n",
       "           1.28264983e+04, 2.11020343e+04, 3.47168682e+04, 5.71158648e+04,\n",
       "           9.39664831e+04, 1.54592774e+05, 2.54334576e+05, 4.18428851e+05,\n",
       "           6.88395207e+05, 1.13254132e+06, 1.86324631e+06, 3.06539530e+06,\n",
       "           5.04315949e+06, 8.29695852e+06, 1.36500781e+07, 2.24569800e+07,\n",
       "           3.69460121e+07, 6.07832313e+07, 1.00000000e+08]),\n",
       "            cv=5),\n",
       "    0.5587511645348955)],\n",
       "  [(RidgeCV(alphas=array([1.00000000e-08, 1.64519059e-08, 2.70665207e-08, 4.45295851e-08,\n",
       "           7.32596543e-08, 1.20526094e-07, 1.98288395e-07, 3.26222201e-07,\n",
       "           5.36697695e-07, 8.82969996e-07, 1.45265393e-06, 2.38989257e-06,\n",
       "           3.93182876e-06, 6.46860766e-06, 1.06420924e-05, 1.75082703e-05,\n",
       "           2.88044415e-05, 4.73887961e-05, 7.79636013e-05, 1.28264983e-04,\n",
       "           2.11020343e-04, 3.47168682e-0...\n",
       "           1.75082703e+03, 2.88044415e+03, 4.73887961e+03, 7.79636013e+03,\n",
       "           1.28264983e+04, 2.11020343e+04, 3.47168682e+04, 5.71158648e+04,\n",
       "           9.39664831e+04, 1.54592774e+05, 2.54334576e+05, 4.18428851e+05,\n",
       "           6.88395207e+05, 1.13254132e+06, 1.86324631e+06, 3.06539530e+06,\n",
       "           5.04315949e+06, 8.29695852e+06, 1.36500781e+07, 2.24569800e+07,\n",
       "           3.69460121e+07, 6.07832313e+07, 1.00000000e+08]),\n",
       "            cv=5),\n",
       "    0.5836233359684575)])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ridge_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e099cf4-4fbc-4c5d-af55-6c0a1101f6ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SingleVariableEnsembleModel:\n",
    "    def __init__(self, models_with_scores):\n",
    "        self.models_with_scores = models_with_scores\n",
    "\n",
    "    def predict(self, X):\n",
    "        total_weight = sum(score for _, score in self.models_with_scores)\n",
    "        prediction = 0\n",
    "        for model, weight in self.models_with_scores:\n",
    "            prediction += (model.predict(X) * weight) / total_weight\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7a2bc5d-b8c9-42a6-9494-6530a68e63c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_with_scores = all_ridge_models['frac_area_harv']\n",
    "\n",
    "ensemble_model = SingleVariableEnsembleModel(models_with_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cae301d-6046-4dcc-9eb1-734711ddf5c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_and_scores = {}\n",
    "\n",
    "for key in all_ridge_models.keys():\n",
    "    models_with_scores = all_ridge_models[key][0] # this gives you the list of tuples\n",
    "    models_and_scores[key] = SingleVariableEnsembleModel(models_with_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db7d97ee-92b8-4b45-aa47-d817f0e128cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frac_area_harv': <__main__.SingleVariableEnsembleModel at 0x7fee4e4fda50>}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_and_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5c40384-e333-49ac-a8f9-61ad459694be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(RidgeCV(alphas=array([1.00000000e-08, 1.64519059e-08, 2.70665207e-08, 4.45295851e-08,\n",
       "         7.32596543e-08, 1.20526094e-07, 1.98288395e-07, 3.26222201e-07,\n",
       "         5.36697695e-07, 8.82969996e-07, 1.45265393e-06, 2.38989257e-06,\n",
       "         3.93182876e-06, 6.46860766e-06, 1.06420924e-05, 1.75082703e-05,\n",
       "         2.88044415e-05, 4.73887961e-05, 7.79636013e-05, 1.28264983e-04,\n",
       "         2.11020343e-04, 3.47168682e-0...\n",
       "         1.75082703e+03, 2.88044415e+03, 4.73887961e+03, 7.79636013e+03,\n",
       "         1.28264983e+04, 2.11020343e+04, 3.47168682e+04, 5.71158648e+04,\n",
       "         9.39664831e+04, 1.54592774e+05, 2.54334576e+05, 4.18428851e+05,\n",
       "         6.88395207e+05, 1.13254132e+06, 1.86324631e+06, 3.06539530e+06,\n",
       "         5.04315949e+06, 8.29695852e+06, 1.36500781e+07, 2.24569800e+07,\n",
       "         3.69460121e+07, 6.07832313e+07, 1.00000000e+08]),\n",
       "          cv=5),\n",
       "  0.635437085494561)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ridge_models['frac_area_harv'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0f2ef68a-1fbe-4054-91d6-dd8b41347753",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mensemble_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrouped_features\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[64], line 6\u001b[0m, in \u001b[0;36mEnsembleModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m----> 6\u001b[0m     total_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msublist\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msublist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels_dict\u001b[38;5;241m.\u001b[39mkeys():\n",
      "Cell \u001b[0;32mIn[64], line 6\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m----> 6\u001b[0m     total_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels_dict\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m sublist)\n\u001b[1;32m      7\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels_dict\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "predictions = ensemble_model.predict(grouped_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac876df-3a86-4934-b520-d8995978a57a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwargs_list = [\n",
    "    { \n",
    "        'target_columns': ['frac_area_harv', 'drought_loss_ind', 'maize', 'log_maize', 'frac_loss_drought'],\n",
    "        'test_size': 0.1,\n",
    "        'categorical_columns':['drought_loss_ind'],\n",
    "        'decision_boundaries': [0.5],\n",
    "        'sea_ids': grouped_features['sea_unq'],  # You'll need to define grouped_features somewhere before this\n",
    "        'validation_size' : 0.1,\n",
    "        'bootstrap' : False,\n",
    "        'n_bootstraps': None,\n",
    "        'block_sample': False,\n",
    "        'n_seas_held_out_val': None,\n",
    "        'n_seas_held_out_test': None,\n",
    "        'random_state': random_state  # This now uses the random_state from the loop\n",
    "    }\n",
    "    for i, random_state in enumerate(random_seeds)\n",
    "]\n",
    "\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    futures = [\n",
    "        executor.submit(train_and_evaluate_models, **kwargs) for kwargs in kwargs_list\n",
    "    ]\n",
    "\n",
    "    predictions_dfs = []\n",
    "    metrics_dfs = []\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing splits\"):\n",
    "        # Get the result\n",
    "        result = future.result()\n",
    "\n",
    "        # Separate the predictions and metrics from the result\n",
    "        predictions_df, metrics_df = result\n",
    "\n",
    "        # Append the results to the corresponding lists\n",
    "        predictions_dfs.append(predictions_df)\n",
    "        metrics_dfs.append(metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d3b341-a89c-49c6-b9b6-57bf6e59b2d1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a71096b5-bd08-42c2-854d-655f56b6b2a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zambia = pd.read_feather(\"/capstone/mosaiks/repos/modeling/data/features_zmb_save.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6085a8b8-7960-43eb-8204-322539fab9e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.520889</td>\n",
       "      <td>0.017403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>1.075246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>2.898772</td>\n",
       "      <td>3.899328</td>\n",
       "      <td>0.019313</td>\n",
       "      <td>0.956588</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>27.800588</td>\n",
       "      <td>-16.343257</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.506241</td>\n",
       "      <td>0.010501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>1.070585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>2.874976</td>\n",
       "      <td>3.857865</td>\n",
       "      <td>0.023663</td>\n",
       "      <td>0.927871</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>27.790588</td>\n",
       "      <td>-16.343257</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.584611</td>\n",
       "      <td>0.021318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006663</td>\n",
       "      <td>1.202663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>2.960961</td>\n",
       "      <td>3.987956</td>\n",
       "      <td>0.021282</td>\n",
       "      <td>0.891021</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>27.780588</td>\n",
       "      <td>-16.353257</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.692933</td>\n",
       "      <td>0.034732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>1.366068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008007</td>\n",
       "      <td>3.097285</td>\n",
       "      <td>4.168679</td>\n",
       "      <td>0.009190</td>\n",
       "      <td>0.847190</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>27.720588</td>\n",
       "      <td>-16.363257</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>0.766315</td>\n",
       "      <td>0.039693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013185</td>\n",
       "      <td>1.480798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008061</td>\n",
       "      <td>3.172538</td>\n",
       "      <td>4.296293</td>\n",
       "      <td>0.017217</td>\n",
       "      <td>0.834277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.730588</td>\n",
       "      <td>-16.363257</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1         2         3         4    5         6         7    8  \\\n",
       "0  0.000185  0.0  0.000639  0.520889  0.017403  0.0  0.003055  1.075246  0.0   \n",
       "1  0.000165  0.0  0.000140  0.506241  0.010501  0.0  0.001828  1.070585  0.0   \n",
       "2  0.000679  0.0  0.001090  0.584611  0.021318  0.0  0.006663  1.202663  0.0   \n",
       "3  0.000502  0.0  0.003195  0.692933  0.034732  0.0  0.009775  1.366068  0.0   \n",
       "4  0.000162  0.0  0.003317  0.766315  0.039693  0.0  0.013185  1.480798  0.0   \n",
       "\n",
       "     9  ...       994       995       996       997       998       999  \\\n",
       "0  0.0  ...  0.004387  2.898772  3.899328  0.019313  0.956588  0.000149   \n",
       "1  0.0  ...  0.003691  2.874976  3.857865  0.023663  0.927871  0.000587   \n",
       "2  0.0  ...  0.007180  2.960961  3.987956  0.021282  0.891021  0.000574   \n",
       "3  0.0  ...  0.008007  3.097285  4.168679  0.009190  0.847190  0.000006   \n",
       "4  0.0  ...  0.008061  3.172538  4.296293  0.017217  0.834277  0.000000   \n",
       "\n",
       "         lon        lat  year  month  \n",
       "0  27.800588 -16.343257  2015      7  \n",
       "1  27.790588 -16.343257  2015      7  \n",
       "2  27.780588 -16.353257  2015      7  \n",
       "3  27.720588 -16.363257  2015      7  \n",
       "4  27.730588 -16.363257  2015      7  \n",
       "\n",
       "[5 rows x 1004 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zambia.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ac1d1",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fcd436",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.maximum(ridge_cv_random.predict(x_train), 0)\n",
    "r2_train = r2_score(y_train, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1)\n",
    "plt.scatter(y_pred, y_train, alpha=1, s=4)\n",
    "plt.xlabel(\"Predicted\", fontsize=15, x = .3)\n",
    "plt.ylabel(\"Ground Truth\", fontsize=15)\n",
    "plt.suptitle(r\"$\\log_{10}(1 + Crop Yield)$\", fontsize=20, y=1.02)\n",
    "plt.title((f\"Model applied to train data n = {len(x_train)}, R$^2$ = {r2_train:0.2f}\"),\n",
    "          fontsize=12, y=1.01)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "ax.axline([0, 0], [1, 1], c = \"k\")\n",
    "\n",
    "plt.gca().spines.right.set_visible(False)\n",
    "plt.gca().spines.top.set_visible(False)\n",
    "\n",
    "\n",
    "# plt.savefig(f'images/{feature_file_name}_train_data.jpg', dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "# the model is plotted with a black 45 degree line that serves as a reference of what a perfect correlation would look like\n",
    "# deviation of the line indicates that there is not a perfect correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbc0486",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training R^2 = {r2_train:0.2f}\\nPearsons r = {pearsonr(y_pred, y_train)[0]:0.2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2550c544-4a28-4d34-841a-837223fa0bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson r^2\n",
    "pearsonr(y_pred, y_train)[0] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c01413-8e64-4ba8-b61e-5fd8c9d10c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative way to calculate Training R^2\n",
    "ridge_cv_random.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff83102",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb42c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = np.maximum(ridge_cv_random.predict(x_test), 0)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_pred, y_test, alpha=1, s=4)\n",
    "plt.xlabel(\"Predicted\", fontsize=15)\n",
    "plt.ylabel(\"Ground Truth\", fontsize=15)\n",
    "plt.suptitle(r\"$\\log_{10}(1 + Crop Yield)$\", fontsize=20, y=1.02)\n",
    "plt.title(f\"Model applied to test data n = {len(x_test)}, R$^2$ = {r2_test:0.2f}\",\n",
    "          fontsize=12, y=1)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "ax.axline([0, 0], [.75, .75], c = \"k\")\n",
    "\n",
    "plt.gca().spines.right.set_visible(False)\n",
    "plt.gca().spines.top.set_visible(False)\n",
    "\n",
    "# plt.savefig(f'images/{feature_file_name}_test_data.jpg', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f6268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Testing set R^2 = {r2_test:0.2f}\")\n",
    "print(f\"Testing set pearsons R = {pearsonr(y_pred, y_test)[0]:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef4215-081f-4537-aade-bf7c3e5d3d93",
   "metadata": {},
   "source": [
    "Summary of both train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78675318-1a34-4c3d-90f8-e738abd6c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.maximum(ridge_cv_random.predict(x_all), 0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.axline([0, 0], [.75, .75], c = \"k\")\n",
    "plt.scatter(y_pred, y_all, alpha=.9, s=15)\n",
    "plt.xlabel(\"Predicted\", fontsize=15)\n",
    "plt.ylabel(\"Observed\", fontsize=15)\n",
    "plt.text(\n",
    "    0, .8, fontsize=15, fontweight=\"bold\",\n",
    "    s=f\"R$^2$={r2_train:0.2f} - Train set\",\n",
    ")\n",
    "plt.text(\n",
    "    0, .75, fontsize=15, fontweight=\"bold\",\n",
    "    s=f\"R$^2$={ridge_cv_random.best_score_:0.2f} - Validation set\",\n",
    ")\n",
    "plt.text(\n",
    "    0, .7, fontsize=15, fontweight=\"bold\",\n",
    "    s=f\"R$^2$={r2_test:0.2f} - Test set\",\n",
    ")\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.gca().spines.right.set_visible(False)\n",
    "plt.gca().spines.top.set_visible(False)\n",
    "\n",
    "# plt.savefig(f'images/{feature_file_name}_all_data.jpg', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a29cb5b",
   "metadata": {},
   "source": [
    "### Use the trained model to predict crop yields over all years from 1km grid-cell resolution features \n",
    "\n",
    "Recall that after we executed imputation on all feature years in the dataframe `features`, we copied the dataframe and named it `features_all_years`. Now we can plug that into the model to visualize how our model performs over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e360ddd6-1c76-4aa0-90cf-3b6ff35b1b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall the object we created earlier, before we split the features by year into those that would train the model \n",
    "# and those that would be fed into the trained model to predict crop yields\n",
    "# in years for which we do not have crop data\n",
    "features_all_years.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd87a870-2e2b-4c03-b65b-d7431fa82f73",
   "metadata": {},
   "source": [
    "In the following chunk, we drop certain columns from `features_all_years` because we only need to feed the feature data into the model to generate predictions. Using the argument `axis = 1`, we specify that we are dropping columns rather than rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ad5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = features_all_years.drop([\n",
    "    'year', \n",
    "    'geometry',\n",
    "    'district',\n",
    "    'crop_perc'\n",
    "], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1331c-9e70-4deb-83a1-ae87cfc7e46b",
   "metadata": {},
   "source": [
    "In the following chunk, we execute the model on the features from the dataframe `features_all_years`. The crop yield predictions for each row populate a new column in the dataframe.\n",
    "\n",
    "The model is run inside the `np.maximum()` function because if we run it without being wrapped inside function, some crop predictions are negative values, but we need them all to be positive because conceptually crop yields cannot be negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad2e993-6581-4a67-ab60-508479ad53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_years['yield_prediction'] = np.maximum(ridge_cv_random.predict(x_all), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4758b-e84a-47c5-a5a5-561d6fbe6823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the dataframe with the new column of predictions\n",
    "features_all_years.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f250da4-4a71-483d-bca9-248b8ecd6901",
   "metadata": {},
   "source": [
    "The dataframe is already a geodataframe, so we do not have to convert it to one before mapping predictions. However, we do need to replace all the zero value crop percentage areas with `NA`. We do this by applying the `mask()` function. This function is similar to an if-else statement. If the value of the `crop_perc` is equal to 0, that value is replaced by the value of the second argument, which is `NA`. If the value of `crop_prec` is _not_ equal to zero, we retain the current value. The argument `inplace = True` executes this replacement in the same cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe0ee44-575a-45b8-ae14-b44ce3290ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_years['yield_prediction'].mask(features_all_years['crop_perc']==0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82712032-c523-4569-9c2a-26f9dea91177",
   "metadata": {},
   "source": [
    "Recall that this dataframe has a geometry column, with latitude and longitude together. In order to map the predicted features, we separate this geometry column into separate `lon` and `lat` columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b20d1-e9f8-43b8-888f-32df0f261592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the longitude and latitude from the geometry column, and make then into independent columns\n",
    "features_all_years['lon'], features_all_years['lat'] = features_all_years.geometry.x, features_all_years.geometry.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eb0d10-ec00-4063-a106-1b73991b9df8",
   "metadata": {},
   "source": [
    "Plot the predicted features for each year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4364cf-5eaf-4cb4-8c77-6bd38de288ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(x, y, c, **kwargs):\n",
    "    plt.scatter(x, y, c=c, s = 1.25)\n",
    "sns.color_palette(\"viridis\", as_cmap=True)\n",
    "g = sns.FacetGrid(\n",
    "    features_all_years, \n",
    "    col=\"year\", \n",
    "    col_wrap = 4, \n",
    "    height=5, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(scatter, \"lon\", \"lat\", \"yield_prediction\")\n",
    "g.set_axis_labels(r\"Yield Prediction\")\n",
    "# save the figure and name the file so that it represents the model parameters that created the predictions\n",
    "# plt.savefig(f'images/{feature_file_name}_all_predictions.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf3917b-9fea-429f-9416-23851b20229e",
   "metadata": {},
   "source": [
    "Plot the model's predicted features summarized to district level. In this visualization, we choose a specific year to examine rather than visualizing all years in one figure. Visualizing the the features summarized to district level is interesting because the crop data resolution provided by Zambia Statistics Agency is at the district level, and therefore it is easier to compare our model results to those ground-truth values when they are summarized to district level as well. Furthermore, our model's crop predictions for the years 2020 and 2021 might be more valuable when summarized to district level if Zambian governments, policy-makers, farmers, and researchers wish to use this data to determine crop imports, exports, and storage according to district summaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dceaaf7-84d7-49b4-a2da-e0086c67c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_years_summary = (\n",
    "    features_all_years\n",
    "    .groupby(['district',\"year\"], as_index = False)['yield_prediction']\n",
    "    .mean()\n",
    "    .set_index('district')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f59be6-5dd0-49f2-bfcc-eb2a2ebea5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join Zambia's shapefile to the summarized features to map the districts\n",
    "# reset the index so it is a properly formatted dataframe\n",
    "features_all_years_summary = features_all_years_summary.join(country_shp).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88e5b61-80c4-4b22-a0fa-5a2dbd415517",
   "metadata": {},
   "source": [
    "Now that the geometries have been converted to districts from points, the geomatries are now polygons. There is still a row for each district for each year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f98fce-e33f-49dc-a17c-c9d52215523a",
   "metadata": {},
   "source": [
    "In order to change the year visualized, simply change the year in the following code and re-run the chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7084cc6b-b854-46f4-b2e2-02ba71482002",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_years_summary[features_all_years_summary.year == 2020].plot(column = \"yield_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45acaeba-bf52-49c3-89e9-00dd307b57e6",
   "metadata": {},
   "source": [
    "Plot a boxplot for each year to visualize the range and quantile distribution of each year's crop predictions, summarized to district level. This enables us to identify years with exceptional disparities between the predicted yields by district. It also allows us to identify years that have many outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beb5eff-a4c8-4a54-85f2-52a1fcf8e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x=\"year\", y=\"yield_prediction\", data = features_all_years_summary)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "plt.ylabel(\"Predicted Yield\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910fe1b-bb79-497a-952a-0c7d3a3e95ee",
   "metadata": {},
   "source": [
    "Visualize the total crop yield predictions by year. This bar chart shows the sum of all the district crop yields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427592b4-686f-4ab1-b781-5f0194dbe081",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=\"year\", y=\"yield_prediction\", data = features_all_years_summary, estimator = sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb543c8f-3e58-4075-b3c2-95804d3c6e7a",
   "metadata": {},
   "source": [
    "## Yield and Residual Plots\n",
    "\n",
    "Create a dataframe of residuals called `residuals_df` from the `features_summary` dataframe. Note that we are _not_ using the predicted crop yields for _all_ years for these residuals, but rather the ground-truth crop yields for just the years through 2018.\n",
    "\n",
    "The residuals give us an idea of the amount of uncertianty that is present in our model. By demeaning the residuals over space, we are able to remove the uncertainty over space and better determine our model performance over time and our uncertainty over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4918a9-c0c4-4a0d-bb32-3ff240200571",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = features_summary.drop(drop_cols, axis = 1)\n",
    "\n",
    "# create empty dataframe to then populate with columns\n",
    "residual_df = pd.DataFrame()\n",
    "\n",
    "residual_df[\"yield_mt\"] = features_summary.yield_mt.to_numpy()\n",
    "residual_df[\"log_yield\"] = np.log10(features_summary.yield_mt.to_numpy() + 1)\n",
    "residual_df[\"prediction\"] = np.maximum(ridge_cv_random.predict(x_all), 0)\n",
    "residual_df[\"residual\"] = residual_df[\"log_yield\"] - residual_df[\"prediction\"]\n",
    "residual_df[\"year\"] = features_summary.year\n",
    "residual_df[\"district\"] = features_summary.district\n",
    "# join the district geometries\n",
    "residual_df = residual_df.join(country_shp, how = \"left\", on = \"district\")\n",
    "\n",
    "# demean by location so we can analyze the data over time\n",
    "residual_df[\"district_yield_mean\"] = residual_df.groupby('district')['log_yield'].transform('mean')\n",
    "residual_df[\"district_prediction_mean\"] = residual_df.groupby('district')['prediction'].transform('mean')\n",
    "residual_df[\"demean_yield\"] = residual_df[\"log_yield\"] - residual_df[\"district_yield_mean\"]\n",
    "residual_df[\"demean_prediction\"] = residual_df[\"prediction\"] - residual_df[\"district_prediction_mean\"]\n",
    "residual_gdf = geopandas.GeoDataFrame(residual_df)\n",
    "\n",
    "residual_gdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a2560-4eca-4061-897f-4bb7e2f7c708",
   "metadata": {},
   "source": [
    "Visualize the residuals for the ground truth crop yields through 2018 with a boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1676a675-bd63-4202-b647-85f0a4fb6152",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "sns.boxplot(x=\"year\", y=\"log_yield\", data=residual_df)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "plt.ylabel(\"Log Yield\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5edb9d-5840-4847-8f04-80f3de8ef0e1",
   "metadata": {},
   "source": [
    "Visualize the residuals as a sum by year with a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1ffa4d-6c2d-4f16-b10d-7ba68bad0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "sns.barplot(x=\"year\", y=\"log_yield\", data=residual_df, estimator = sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd0e82a-7842-4ffe-aa54-0998a766d162",
   "metadata": {},
   "source": [
    "Visualize the crop yield residuals by year as a histogram to determine how they are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd79b57f-1fcc-4364-ba15-db3eed9e7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    residual_gdf, \n",
    "    col=\"year\", \n",
    "#     col_wrap = 3, \n",
    "    height=4, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(sns.histplot, \"yield_mt\", bins = 20)\n",
    "g.set_axis_labels(\"Yield (MT)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dd3e09-071a-4bb3-b706-9843ef4e58cc",
   "metadata": {},
   "source": [
    "Visualize the log-transformed crop yield residuals by year as a histogram to compare how they are distributed after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51204a02-7ac4-49bc-b4a6-d4d89f18b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    residual_gdf, \n",
    "    col=\"year\", \n",
    "#     col_wrap = 3, \n",
    "    height=4, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(sns.histplot, \"log_yield\", bins = 20)\n",
    "g.set_axis_labels(r\"$\\log_{10}(1 + Crop Yield)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b1529f-abd6-4dde-9af2-7128cfd908ce",
   "metadata": {},
   "source": [
    "#### Crop prediction histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f611311c-5df0-4cbf-b3ac-37931e00acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    residual_gdf, \n",
    "    col=\"year\", \n",
    "#     col_wrap = 3, \n",
    "    height=4, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(sns.histplot, \"prediction\", bins = 20)\n",
    "g.set_axis_labels(r\"Crop yield predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da7448e-ad5f-488d-bde5-dab420c74859",
   "metadata": {},
   "source": [
    "#### Residual histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0628f0-fce2-47ff-b96a-8a4deec322ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    residual_gdf, \n",
    "    col=\"year\", \n",
    "#     col_wrap = 3, \n",
    "    height=4, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(sns.histplot, \"residual\", bins = 20)\n",
    "g.set_axis_labels(r\"Residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f5d92d-0165-409b-aa92-e8224fce2553",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_gdf.residual.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88730cab-d02a-4df4-9d05-bbbf6b42eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_gdf.residual.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbac5aa-4029-43e2-9d94-dbaa930aa87b",
   "metadata": {},
   "source": [
    "#### Log crop yield vs residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ec42e2-81d5-43f4-ab32-926f5f0ffc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    residual_gdf, \n",
    "    col=\"year\", \n",
    "#     col_wrap = 3, \n",
    "    height=4, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(sns.scatterplot, \"log_yield\", \"residual\")\n",
    "g.set_axis_labels(r\"$\\log_{10}(1 + Crop Yield)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063416fe-51cb-4505-a5c1-59864bf277b3",
   "metadata": {},
   "source": [
    "#### District residuals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f7002-7619-4fc4-bcb8-98f1317cd94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if satellite == 'landsat-8-c2-l2':\n",
    "    fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))\n",
    "    ax1 = (residual_gdf[residual_gdf.year == 2014]\n",
    "           .plot(ax = ax1, column = \"residual\", legend = True, norm=colors.Normalize(vmin= -0.4, vmax=0.4), cmap = \"BrBG\")\n",
    "           .set_title(\"2014 Residuals\"))\n",
    "    ax2 = (residual_gdf[residual_gdf.year == 2015]\n",
    "           .plot(ax = ax2, column = \"residual\", legend = True, norm=colors.Normalize(vmin= -0.4, vmax=0.4), cmap = \"BrBG\")\n",
    "           .set_title(\"2015 Residuals\"))\n",
    "else:\n",
    "    pass\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(nrows=1, ncols=3, figsize=(20, 5))\n",
    "ax1 = (residual_gdf[residual_gdf.year == 2016]\n",
    "       .plot(ax = ax1, column = \"residual\", legend = True, norm=colors.Normalize(vmin= -0.4, vmax=0.4), cmap = \"BrBG\")\n",
    "       .set_title(\"2016 Residuals\"))\n",
    "ax2 = (residual_gdf[residual_gdf.year == 2017]\n",
    "       .plot(ax = ax2, column = \"residual\", legend = True, norm=colors.Normalize(vmin= -0.4, vmax=0.4), cmap = \"BrBG\")\n",
    "       .set_title(\"2017 Residuals\"))\n",
    "ax3 = (residual_gdf[residual_gdf.year == 2018]\n",
    "       .plot(ax = ax3, column = \"residual\", legend = True, norm=colors.Normalize(vmin= -0.4, vmax=0.4), cmap = \"BrBG\")\n",
    "       .set_title(\"2018 Residuals\"))\n",
    "\n",
    "caption = \"A positive value is an underestimated prediction (the prediction is lower than the actual yield), a negative value is an over estimated prediction\"\n",
    "plt.figtext(0.5, 0.01, caption, wrap=True, horizontalalignment='center', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c06eb6d-6b28-4493-982f-c2bdc6e18517",
   "metadata": {},
   "source": [
    "#### Difference from the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e53cc-050b-4718-8882-410d02c5aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    residual_gdf, \n",
    "    col=\"year\", \n",
    "#     col_wrap = 3, \n",
    "    height=4, \n",
    "    aspect=1\n",
    ")\n",
    "g.map(sns.scatterplot, \"demean_yield\", \"demean_prediction\")\n",
    "g.set_axis_labels('Difference from Yield Mean', 'Difference from Prediction Mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c993e12-982a-42e9-8c35-28770ab2b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize= (6, 5))\n",
    "ax.axline([-.2, -.2], [.2, .2], c = \"k\")\n",
    "plt.scatter(residual_gdf.demean_yield, residual_gdf.demean_prediction)\n",
    "plt.title(\"Demeaned truth and predictions by district\")\n",
    "plt.xlabel('Difference from Yield Mean')\n",
    "plt.ylabel('Difference from Predictions Mean')\n",
    "r_squared = r2_score(residual_gdf[\"demean_yield\"], residual_gdf[\"demean_prediction\"])\n",
    "plt.text(\n",
    "    -0.2,\n",
    "    .18,\n",
    "    s=f\"Demeaned R$^2$ = {r_squared:0.2f}\",\n",
    "    fontsize=15,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "plt.savefig(f'images/{feature_file_name}_demean.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167f9228-34b2-4f04-b4b0-d47e78542e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for yr in range(year_start+1, 2018):\n",
    "    r_squared = r2_score(residual_gdf[residual_gdf.year == yr][\"demean_yield\"], residual_gdf[residual_gdf.year == yr][\"demean_prediction\"])\n",
    "    pearson_r = pearsonr(residual_gdf[residual_gdf.year == yr][\"demean_yield\"], residual_gdf[residual_gdf.year == yr][\"demean_prediction\"])\n",
    "    \n",
    "    print(yr, f\"    R^2: {r_squared:.2f}\\n\",\n",
    "          f\"Pearson's r: {pearson_r[0]:.2f}\\n\", \n",
    "          sep = \"\")\n",
    "    \n",
    "r_squared = r2_score(residual_gdf[\"demean_yield\"], residual_gdf[\"demean_prediction\"])\n",
    "pearson_r = pearsonr(residual_gdf[\"demean_yield\"], residual_gdf[\"demean_prediction\"])\n",
    "print(f\"All     R^2: {r_squared:.2f}\\n\",\n",
    "      f\"Pearson's r: {pearson_r[0]:.2f}\", sep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034bd1d1-4490-4801-a729-331c00e0a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = round(pearson_r[0] ** 2, 2)\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e907866-1c8b-41dc-a346-01c0a53ee3fb",
   "metadata": {},
   "source": [
    "#### Join residuals to the features for _all_ years to visualize the residuals of the features before they were summarized to district level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f0e606-93a8-477f-b15d-b9a98d2a84ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = (\n",
    "    features_all_years_summary\n",
    "    .set_index(['district', 'year'])\n",
    "    .join(residual_df\n",
    "          .drop('geometry', axis = 1)\n",
    "          .set_index(['district', 'year'])\n",
    "         )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "complete_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f045cfe-8479-41c7-bd04-9247843e4094",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "tidy = complete_df.melt(id_vars='year').rename(columns=str.title)\n",
    "tidy = tidy[tidy.Variable.isin(['yield_prediction', 'log_yield'])]\n",
    "sns.barplot(x='Year', y='Value', hue='Variable', data=tidy, ax=ax1, ci = None)\n",
    "sns.despine(fig)\n",
    "\n",
    "h, l = ax1.get_legend_handles_labels()\n",
    "ax1.legend(h, ['Predicted Yield', 'Observed Yield'],loc='lower left')\n",
    "\n",
    "plt.savefig(f'images/{feature_file_name}_yield_pred.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4149c18b-e563-4575-9c13-db636db64af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=\"year\", y=\"yield_prediction\", data=complete_df, estimator = sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38476b4e-d3b5-4f79-8d2d-651d6416900a",
   "metadata": {},
   "source": [
    "### Congratulations on completing this analysis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosaiks-modeling",
   "language": "python",
   "name": "mosaiks-modeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
